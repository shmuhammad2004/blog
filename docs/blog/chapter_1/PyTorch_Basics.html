<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.570">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-04-18">
<meta name="description" content="This is a non-nonse tutorial about PyTorch Tensor">

<title>Shamsuddeen Hassan Muhammad’s Blog - Pytorch Tensor 101</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

<script type="text/javascript">

(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-124900795-1', 'auto');

ga('send', {
  hitType: 'pageview',
  'anonymizeIp': true,
});
</script>
<script defer="" data-domain="ivelasq.rbind.io" src="https://plausible.io/js/plausible.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="twitter:title" content="Shamsuddeen Hassan Muhammad’s Blog - Pytorch Tensor 101">
<meta name="twitter:description" content="This is a non-nonse tutorial about PyTorch…">
<meta name="twitter:image" content="https://shmuhammadblog.github.io/blog/chapter_1/book_pic.png">
<meta name="twitter:creator" content="Shamsuddeen Hassan Muhammad">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Shamsuddeen Hassan Muhammad</span>
  </a>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="dropdown-header">
 NLP Researcher and Data Scientist</li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html">Blog</a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../til.html">Today I Learned</a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="button" data-bs-toggle="dropdown" aria-expanded="false">Resources</a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="../../NLP.html">
 <span class="dropdown-text">NLP</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../DL.html">
 <span class="dropdown-text">ML/DL</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../DL.html">
 <span class="dropdown-text">Scientific Writing and Research</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../DL.html">
 <span class="dropdown-text">Python</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../DL.html">
 <span class="dropdown-text">Visualization</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../DL.html">
 <span class="dropdown-text">R</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/Shmuhammadd"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/shmuhammad2004"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/shmuhammad/"><i class="bi bi-linkedin" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"><i class="bi bi-rss" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Pytorch Tensor 101</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Pytorch</div>
    <div class="quarto-category">Books</div>
  </div>
  </div>

<div>
  <div class="description">
    This is a non-nonse tutorial about PyTorch Tensor
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">April 18, 2022</p>
    </div>
  </div>
    
  </div>
  

</header>

<section id="pytorch-basics" class="level1">
<h1>PyTorch Basics</h1>
<p>Tutorial Objectives</p>
<ul>
<li>Learn about PyTorch and tensors</li>
<li>Tensor Manipulations</li>
<li>Data Loading</li>
<li>GPUs and Cuda Tensors</li>
<li>Train NaiveNet</li>
</ul>
<section id="pytorch" class="level2">
<h2 class="anchored" data-anchor-id="pytorch">PyTorch</h2>
<p>PyTorch is a Python-based open source and scientific computing package for building neural networks. It is dynamic graph-based framework that allows you to define your neural network in a way that is easy to understand and debug. Today, PyTorch is the <a href="https://paperswithcode.com/trends">most used deep learning framework</a> and mostly use by researchers and engineers.</p>
<p><img src="./pytorch_most_used.png" class="img-fluid"></p>
<ul>
<li><p>PyTorch support GPU acceleration (making your code run faster) behind the scenes, better than NumPy</p></li>
<li><p>PyTorch provides Autograd for automatic differentiation, which means that your code is automatically differentiated and you can use it to do backpropagation</p></li>
</ul>
</section>
<section id="pytoch-installation" class="level2">
<h2 class="anchored" data-anchor-id="pytoch-installation">Pytoch Installation</h2>
<p>Before you installed Pytorch, you need to install the following dependencies: Package Manager (e.g.&nbsp;pip, conda), Python, Numpy. For more information, please refer to the <a href="https://pytorch.org/">Pytorch documentation</a>.</p>
<p>For me, I am using mac and conda as package manager, I therefore run the following command</p>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>conda install pytorch torchvision torchaudio <span class="op">-</span>c pytorch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="verification" class="level2">
<h2 class="anchored" data-anchor-id="verification">VERIFICATION</h2>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1234</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>torch.__version__</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/anaconda3/envs/datascience/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>'1.13.0.dev20220611'</code></pre>
</div>
</div>
</section>
<section id="what-is-tensor" class="level2">
<h2 class="anchored" data-anchor-id="what-is-tensor">What is Tensor</h2>
<ul>
<li><p>Tensor are the standard way of representing data in Pytorch, such as text, images, and audio.</p></li>
<li><p>Their job is to represent data in a numerical way.</p></li>
</ul>
<p><img src="./tensor_represent_data.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>You could have a vector [3, 2] to describe [bedrooms, bathrooms] in your house. Or you could have [3, 2, 2] to describe [bedrooms, bathrooms, car_parks] in your house.</p>
</blockquote>
<p><img src="./tensor_loop.png" class="img-fluid"></p>
</section>
</section>
<section id="is-tensor-all-you-need" class="level1">
<h1>is Tensor all you need?</h1>
<ul>
<li><p>Data Structure for holding data:</p>
<ul>
<li><p>Python List,</p></li>
<li><p>Numpy Array, and</p></li>
<li><p>Torch Tensor</p></li>
</ul></li>
<li><p>Let us remember the basic of data structures in Python (List and Numpy Array) before we start using Pytorch Tensor</p></li>
</ul>
<section id="from-python-lists-to-numpy-array" class="level3">
<h3 class="anchored" data-anchor-id="from-python-lists-to-numpy-array">From Python lists to Numpy Array</h3>
<ul>
<li>Python does not have built-in support for Arrays, but Python Lists can be used instead.</li>
</ul>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>a_list <span class="op">=</span> [<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>] <span class="co">#A list is the Python equivalent of an array</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>a_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>[1, 3, 4]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_list)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>list</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>a_list[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>a_numpy <span class="op">=</span> np.array([<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">4</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>a_numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>array([1, 3, 4])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_numpy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>numpy.ndarray</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>a_numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>array([1, 3, 4])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>a_numpy[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>1</code></pre>
</div>
</div>
</section>
<section id="why-numpy" class="level3">
<h3 class="anchored" data-anchor-id="why-numpy">Why numpy?</h3>
<ul>
<li><p>Size - Numpy data structures take up less space</p></li>
<li><p>Performance - they have a need for speed and are faster than lists</p></li>
<li><p>Functionality - SciPy and NumPy have optimized functions such as linear algebra operations built in.</p></li>
</ul>
<p><img src="./contiguous.png" class="img-fluid"></p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>size_of_vec <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pure_python_version():</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    t1 <span class="op">=</span> time.time()</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> <span class="bu">range</span>(size_of_vec)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> <span class="bu">range</span>(size_of_vec)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> [X[i] <span class="op">+</span> Y[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X)) ]</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> time.time() <span class="op">-</span> t1</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> numpy_version():</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    t1 <span class="op">=</span> time.time()</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> np.arange(size_of_vec)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> np.arange(size_of_vec)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    Z <span class="op">=</span> X <span class="op">+</span> Y</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> time.time() <span class="op">-</span> t1</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>t1 <span class="op">=</span> pure_python_version()</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>t2 <span class="op">=</span> numpy_version()</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t1, t2)</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Numpy is in this example "</span> <span class="op">+</span> <span class="bu">str</span>(t1<span class="op">/</span>t2) <span class="op">+</span> <span class="st">" faster!"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.0001919269561767578 3.5762786865234375e-05
Numpy is in this example 5.366666666666666 faster!</code></pre>
</div>
</div>
</section>
<section id="from-numpy-array-to-torch-tensor" class="level3">
<h3 class="anchored" data-anchor-id="from-numpy-array-to-torch-tensor">From Numpy Array to Torch Tensor</h3>
<ul>
<li><p>Tensors are like arrays, both are data structures that are used to store data.</p></li>
<li><p>Tensor support GPU acceleration (Speed) and Gradients (Backpropagation)</p></li>
<li><p>Numpy arrays are mainly used in typical machine learning algorithms whereas pytorch tensors are mainly used in deep learning which requires heavy matrix computation</p></li>
</ul>
<section id="are-tensors-really-like-numpy-arrays" class="level4">
<h4 class="anchored" data-anchor-id="are-tensors-really-like-numpy-arrays">Are Tensors Really like Numpy Arrays?</h4>
<ul>
<li>Yes, they are. Let us see how they created</li>
</ul>
<blockquote class="blockquote">
<p>Numpy</p>
</blockquote>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>a_numpy <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]]) <span class="co"># Create a numpy array</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_numpy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[[1 2 3]
 [2 3 4]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>a_numpy.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>(2, 3)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>a_numpy.size</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>6</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>a_numpy.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>dtype('int64')</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_numpy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>numpy.ndarray</code></pre>
</div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>a_numpy[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>array([1, 2, 3])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Tensor</p>
</blockquote>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>a_tensor <span class="op">=</span> torch.Tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], [<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>]]) <span class="co"># Create a PyTorch tensor</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2., 3.],
        [2., 3., 4.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>a_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>a_tensor.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>a_tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>torch.float32</code></pre>
</div>
</div>
<div class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(a_tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>torch.Tensor</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>A tensor is an array: that is, a data structure that stores a collection of numbers that are accessible individually using an index, and that can be indexed with multiple indices.</p>
</blockquote>
<blockquote class="blockquote">
<p>So, the most important difference between the two frameworks is naming. Numpy calls tensors (high dimensional matrices or vectors) arrays while in PyTorch there’s just called tensors. Everything else is quite similar.</p>
</blockquote>
</section>
</section>
<section id="but-wait-tensors-offer-much-more-than-just-a-data-structure." class="level2">
<h2 class="anchored" data-anchor-id="but-wait-tensors-offer-much-more-than-just-a-data-structure.">But, wait Tensors offer much more than just a data structure.</h2>
<ul>
<li><p>GPU acceleration , which is a great advantage for deep learning</p></li>
<li><p>distribute operations on multiple devices or machines, and</p></li>
<li><p>keep track of the graph of computations that created them ( usefull for backpropagation)</p></li>
</ul>
</section>
<section id="let-us-learn-more-about-tensor" class="level2">
<h2 class="anchored" data-anchor-id="let-us-learn-more-about-tensor">Let us Learn more about Tensor</h2>
<blockquote class="blockquote">
<p>Tensors are generalization of vectors and matrices to an arbitrary number of dimensions.</p>
</blockquote>
<p><img src="./tensor_generalization.png" class="img-fluid"></p>
<p><img src="./tensor.png" class="img-fluid"></p>
<section id="so-what-can-we-do-with-tensors" class="level3">
<h3 class="anchored" data-anchor-id="so-what-can-we-do-with-tensors">So, what can we do with Tensors?</h3>
<p>Various operations are available on tensors.</p>
<ul>
<li><p>Creating tensors</p></li>
<li><p>Operations with tensors</p></li>
<li><p>Indexing, slicing, and joining with tensors Computing gradients with tensors</p></li>
<li><p>Using CUDA/MPS tensors with GPUs</p></li>
</ul>
</section>
</section>
<section id="creating-tensors" class="level2">
<h2 class="anchored" data-anchor-id="creating-tensors">Creating Tensors</h2>
<ul>
<li><p>PyTorch allows us to create tensors in many different ways using the torch package.</p></li>
<li><p>The following are some of the ways to create tensors:</p></li>
</ul>
<section id="creating-random-tensor-with-a-specific-size" class="level5">
<h5 class="anchored" data-anchor-id="creating-random-tensor-with-a-specific-size">1: Creating Random Tensor with a specific size</h5>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>a_random <span class="op">=</span> torch.Tensor(size <span class="op">=</span> (<span class="dv">3</span>,<span class="dv">4</span>)) <span class="co"># Create a random tensor</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a_numpy = np.array([3,4])</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.0000e+00, 2.0000e+00, 0.0000e+00, 2.0000e+00],
        [4.8673e-39, 4.5810e-41, 6.1522e-36, 1.4013e-45],
        [8.4015e-40, 4.5810e-41, 4.7625e-10, 4.5810e-41]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.shape)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.size())</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(a_random))</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.<span class="bu">type</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 4])
torch.Size([3, 4])
&lt;class 'torch.Tensor'&gt;
torch.FloatTensor</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: .shape is an alias for .size(), and was added to closely match numpy !</p>
</blockquote>
<blockquote class="blockquote">
<p>Note: The default tensor type when you use the torch.Tensor constructor is torch.FloatTensor.</p>
</blockquote>
<p>Infact, <code>torch.Tensor</code> is an alias for the default tensor type (torch.FloatTensor).</p>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>a_random <span class="op">=</span> torch.FloatTensor((<span class="dv">3</span>,<span class="dv">4</span>)) <span class="co"># Create a random tensor</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.<span class="bu">type</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.FloatTensor</code></pre>
</div>
</div>
<ul>
<li><p>But, what if I want my tensor to represent the data type I use?</p>
<ul>
<li><code>torch.tensor</code> constructor infers the dtype automatically</li>
</ul></li>
</ul>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>a_random <span class="op">=</span> torch.tensor((<span class="dv">3</span>,<span class="dv">4</span>)) <span class="co"># Create a random tensor</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random.dtype)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.int64</code></pre>
</div>
</div>
<p>But, you can also specify the dtype explicitly.</p>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>a_torch <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_torch.<span class="bu">type</span>()) <span class="co"># Tensor type</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.FloatTensor</code></pre>
</div>
</div>
<p>I would recommend to stick to torch.tensor, if you would like to change the type, you can change</p>
<ul>
<li>What of if I have existing Tensor and what should I do with it?</li>
</ul>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>a_torch <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_torch.<span class="bu">type</span>()) <span class="co"># Tensor type</span></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_torch.size()) <span class="co"># Tensor Size</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.LongTensor
torch.Size([3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>a_short <span class="op">=</span>  a_torch.short() <span class="co"># Convert to short, float(), </span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_short.<span class="bu">type</span>()) <span class="co"># Tensor type</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.ShortTensor</code></pre>
</div>
</div>
<p><a href="https://pytorch.org/docs/stable/tensors.html#data-types">See different Pytorch Data Types</a>: Torch defines 10 tensor types with CPU and GPU variants:</p>
<ul>
<li><p>The most common type (and generally the default) is torch.float32 or torch.float. This is referred to as “32-bit floating point”.</p></li>
<li><p>But there’s also 16-bit floating point (torch.float16 or torch.half) and 64-bit floating point (torch.float64 or torch.double).</p></li>
<li><p>The reason for all of these is to do with precision in computing. Precision is the amount of detail used to describe a number.</p></li>
<li><p>The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.</p></li>
<li><p>This matters in deep learning and numerical computing because you’re making so many operations, the more detail you have to calculate on, the more compute you have to use.</p></li>
<li><p>So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).</p></li>
</ul>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>float_16_tensor <span class="op">=</span> torch.tensor([<span class="fl">3.0</span>, <span class="fl">6.0</span>, <span class="fl">9.0</span>],</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>                               dtype<span class="op">=</span>torch.float16) <span class="co"># torch.half would also work</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>float_16_tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>torch.float16</code></pre>
</div>
</div>
</section>
<section id="creating-tensors-from-random-numbers" class="level5">
<h5 class="anchored" data-anchor-id="creating-tensors-from-random-numbers">2: Creating Tensors from Random Numbers</h5>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>a_random_torch <span class="op">=</span> torch.randn(<span class="dv">2</span>, <span class="dv">3</span>) <span class="co"># uniform random distribution numbers between 0 and 1</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a_numpy_rand = np.random.randn(2,3) #numpy random normal distribution</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>(<span class="dv">2</span>,<span class="dv">3</span>)  </span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random_torch)</span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co"># print(a_numpy_rand)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0.0461,  0.4024, -1.0115],
        [ 0.2167, -0.6123,  0.5036]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>a_random_torch <span class="op">=</span> torch.rand(<span class="dv">2</span>, <span class="dv">3</span>) <span class="co"># random normal distribution</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co"># a_numpy_rand = np.random.rand(2,3) </span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_random_torch)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># print(a_numpy_rand)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.7749, 0.8208, 0.2793],
        [0.6817, 0.2837, 0.6567]])</code></pre>
</div>
</div>
</section>
<section id="creating-a-filled-tensor" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-filled-tensor">3: Creating a filled tensor</h3>
<div class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>a_same_scalar <span class="op">=</span> torch.zeros(<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_same_scalar)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_same_scalar.size())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])
torch.Size([10, 5])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>torch.ones(<span class="dv">6</span>, <span class="dv">10</span>) <span class="co"># torch.ones(size=(6, 10)) </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>a_zero <span class="op">=</span> torch.zeros(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a_zero)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>a_zero.fill_(<span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([[5., 5., 5.],
        [5., 5., 5.]])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Any PyTorch method with an underscore (_) refers to an in­place operation;</p>
</blockquote>
<div class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>a_zero.fill_(<span class="dv">5</span>).size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>torch.Size([2, 3])</code></pre>
</div>
</div>
<section id="creating-and-initializing-a-tensor-from-lists" class="level4">
<h4 class="anchored" data-anchor-id="creating-and-initializing-a-tensor-from-lists">4: Creating and initializing a tensor from lists</h4>
<div class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>a_list <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>a_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>a_list <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>], </span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a>                      [<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]])</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>a_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([[1, 2, 3],
        [4, 5, 6]])</code></pre>
</div>
</div>
</section>
<section id="creating-and-initializing-a-tensor-from-numpy-arrays" class="level4">
<h4 class="anchored" data-anchor-id="creating-and-initializing-a-tensor-from-numpy-arrays">5: Creating and initializing a tensor from numpy arrays</h4>
<ul>
<li>The values can either come from a list, as in the preceding example, or from a NumPy array</li>
</ul>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>numpy_array <span class="op">=</span> np.random.rand(<span class="dv">2</span>, <span class="dv">3</span>) </span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>numpy_array</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>array([[0.31112954, 0.99590158, 0.73157034],
       [0.6366771 , 0.1105546 , 0.84468547]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="bu">type</span>(numpy_array)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>numpy.ndarray</code></pre>
</div>
</div>
<div class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>torch_tensor <span class="op">=</span> torch.from_numpy(numpy_array)</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>torch_tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([[0.3111, 0.9959, 0.7316],
        [0.6367, 0.1106, 0.8447]], dtype=torch.float64)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>torch_tensor.<span class="bu">type</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>'torch.DoubleTensor'</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>DoubleTensor instead of the default FloatTensor (see the next section). This corresponds with the data type of the NumPy random matrix, a float64,</p>
</blockquote>
<p>You can always convert from PyTorch tensors to Numpy arrays using the numpy function torch.numpy().</p>
</section>
<section id="creating-a-range-and-tensors-like" class="level4">
<h4 class="anchored" data-anchor-id="creating-a-range-and-tensors-like">6: Creating a range and tensors like</h4>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use torch.arange(), torch.range() is deprecated </span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>zero_to_ten_deprecated <span class="op">=</span> torch.<span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># Note: this may return an error in the future</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/1h/b7ng0kgj3w78mg7n8k7q7rch0000gn/T/ipykernel_83392/2171007885.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).
  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a range of values 0 to 10</span></span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>zero_to_ten <span class="op">=</span> torch.arange(start<span class="op">=</span><span class="dv">0</span>, end<span class="op">=</span><span class="dv">10</span>, step<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>zero_to_ten</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
</section>
<section id="creating-tensor-of-type-with-the-same-shape-as-another-tensor." class="level4">
<h4 class="anchored" data-anchor-id="creating-tensor-of-type-with-the-same-shape-as-another-tensor.">7:Creating tensor of type with the same shape as another tensor.</h4>
<div class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also create a tensor of zeros similar to another tensor</span></span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a>ten_zeros <span class="op">=</span> torch.zeros_like(<span class="bu">input</span><span class="op">=</span>zero_to_ten) <span class="co"># will have same shape</span></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>ten_zeros</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also create a tensor of zeros similar to another tensor</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>ten_zeros <span class="op">=</span> torch.ones_like(<span class="bu">input</span><span class="op">=</span>zero_to_ten) <span class="co"># will have same shape</span></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>ten_zeros</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</code></pre>
</div>
</div>
</section>
<section id="dimensions-of-a-tensor-using-the-ndim-attribute" class="level4">
<h4 class="anchored" data-anchor-id="dimensions-of-a-tensor-using-the-ndim-attribute">Dimensions of a tensor using the ndim attribute</h4>
<div class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>scalar <span class="op">=</span> torch.tensor(<span class="dv">7</span>)</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>scalar</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor(7)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>scalar.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>0</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Scalar</span></span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>vector <span class="op">=</span> torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>])</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a>vector</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="50">
<pre><code>tensor([1, 2, 3, 4])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>vector.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>1</code></pre>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>MATRIX <span class="op">=</span> torch.tensor([[<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>],</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>                       [<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>]])</span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a>MATRIX</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([[1, 2, 3, 4],
        [5, 6, 7, 8]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>MATRIX.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>2</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>You can tell the number of dimensions a tensor in PyTorch has by the number of square brackets on the outside ([) and you only need to count one side of the brackets.</p>
</blockquote>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>TENSOR <span class="op">=</span> torch.tensor([[[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>],</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">9</span>],</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>                        [<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">5</span>]]])</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a>TENSOR</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>tensor([[[1, 2, 3],
         [3, 6, 9],
         [2, 4, 5]]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>TENSOR.ndim</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>3</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>In practice, you’ll often see scalars and vectors denoted as lowercase letters such as y or a. And matrices and tensors denoted as uppercase letters such as X or W</p>
</blockquote>
</section>
</section>
<section id="creating-named-tensors" class="level3">
<h3 class="anchored" data-anchor-id="creating-named-tensors">Creating Named Tensors</h3>
<ul>
<li><p>Named Tensors allow users to give explicit names to tensor dimensions.</p></li>
<li><p>In most cases, operations that take dimension parameters will accept dimension names, avoiding the need to track dimensions by position.</p></li>
</ul>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>torch.zeros(<span class="dv">2</span>, <span class="dv">3</span>, names<span class="op">=</span>(<span class="st">'N'</span>, <span class="st">'C'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/1h/b7ng0kgj3w78mg7n8k7q7rch0000gn/T/ipykernel_83392/697701580.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1654931446436/work/c10/core/TensorImpl.h:1489.)
  torch.zeros(2, 3, names=('N', 'C'))</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor([[0., 0., 0.],
        [0., 0., 0.]], names=('N', 'C'))</code></pre>
</div>
</div>
<ul>
<li>Use names to access tensor dimensions.</li>
</ul>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb112"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a>imgs <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span> , names<span class="op">=</span>(<span class="st">'N'</span>, <span class="st">'C'</span>, <span class="st">'H'</span>, <span class="st">'W'</span>)) </span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a>imgs.names</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>('N', 'C', 'H', 'W')</code></pre>
</div>
</div>
<div class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>imgs.names[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>'N'</code></pre>
</div>
</div>
<div class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>imgs.names[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>'C'</code></pre>
</div>
</div>
</section>
</section>
<section id="indexing-tensors" class="level2">
<h2 class="anchored" data-anchor-id="indexing-tensors">Indexing tensors</h2>
<p>Indexing a tensor is similar to indexing a list.</p>
<blockquote class="blockquote">
<p>List indexing:</p>
</blockquote>
<div class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>some_list <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">6</span>))</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>some_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>[0, 1, 2, 3, 4, 5]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>some_list[<span class="dv">1</span>:<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>[1, 2, 3]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb122"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a>some_list[<span class="dv">1</span>:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>[1, 2, 3, 4, 5]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>some_list[<span class="dv">1</span>:<span class="dv">4</span>:<span class="dv">2</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>[1, 3]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb126"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a>some_list[:]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>[0, 1, 2, 3, 4, 5]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(some_list[:<span class="dv">4</span>])</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(some_list[:<span class="op">-</span><span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0, 1, 2, 3]
[0, 1, 2, 3, 4]</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Pytorch tensor indexing:</p>
</blockquote>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>torch_list <span class="op">=</span> torch.tensor(some_list)</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>torch_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>tensor([0, 1, 2, 3, 4, 5])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>torch_list[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>tensor(0)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb134"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>torch_list[<span class="dv">1</span>:<span class="dv">4</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
</section>
<section id="transposing-tensors" class="level2">
<h2 class="anchored" data-anchor-id="transposing-tensors">Transposing Tensors</h2>
<p>Transposing 2D tensors is a simple operation using <code>t</code></p>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb136"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>points <span class="op">=</span> torch.tensor([[<span class="fl">4.0</span>, <span class="fl">1.0</span>], [<span class="fl">5.0</span>, <span class="fl">3.0</span>], [<span class="fl">2.0</span>, <span class="fl">1.0</span>]])</span>
<span id="cb136-2"><a href="#cb136-2" aria-hidden="true" tabindex="-1"></a>points</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>tensor([[4., 1.],
        [5., 3.],
        [2., 1.]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb138"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb138-1"><a href="#cb138-1" aria-hidden="true" tabindex="-1"></a>points_t <span class="op">=</span> points.t()</span>
<span id="cb138-2"><a href="#cb138-2" aria-hidden="true" tabindex="-1"></a>points_t</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>tensor([[4., 5., 2.],
        [1., 3., 1.]])</code></pre>
</div>
</div>
<p>You can also transpose 3D and higher tensors using the <code>transpose</code> method by specifying the two dimensions along which transposing (flipping shape and stride) should occur:</p>
<div class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>some_t <span class="op">=</span> torch.ones(<span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>transpose_t <span class="op">=</span> some_t.transpose(<span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>some_t.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>torch.Size([3, 4, 5])</code></pre>
</div>
</div>
</section>
<section id="manipulating-tensors-tensor-operations" class="level2">
<h2 class="anchored" data-anchor-id="manipulating-tensors-tensor-operations">Manipulating tensors (tensor operations)</h2>
<ul>
<li><p>In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.</p></li>
<li><p>A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.</p></li>
<li><p>After you have created your tensors, you can operate on them like you would do with traditional programming language types, like +, ­, *, /.</p></li>
</ul>
<blockquote class="blockquote">
<p>Addition: torch.add(tensor1, tensor2)</p>
</blockquote>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb142"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor of values and add a number to it</span></span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">+</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>tensor([11, 12, 13])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb144"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiply it by 10</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">*</span> <span class="dv">10</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="71">
<pre><code>tensor([10, 20, 30])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb146"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subtract and reassign</span></span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> tensor <span class="op">-</span> <span class="dv">10</span></span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a>tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>tensor([-9, -8, -7])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb148"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>tensor([-0.4790,  0.8539, -0.2285,  0.3081])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>PyTorch also has a bunch of built-in functions like torch.mul() (short for multiplcation) and torch.add() to perform basic operations.</p>
</blockquote>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb150"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also use torch functions</span></span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>torch.multiply(tensor, <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([10, 20, 30])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb152"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a>torch.add(tensor, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>tensor([21, 22, 23])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>torch.div(tensor, <span class="dv">20</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>tensor([0.0500, 0.1000, 0.1500])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb156"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a>torch.div(tensor, <span class="dv">20</span>, rounding_mode<span class="op">=</span><span class="st">'trunc'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>tensor([0, 0, 0])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>torch.div(tensor, <span class="dv">20</span>, rounding_mode<span class="op">=</span><span class="st">'floor'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="78">
<pre><code>tensor([0, 0, 0])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Sum: torch.sum(tensor)</p>
</blockquote>
<div class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb160"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb160-2"><a href="#cb160-2" aria-hidden="true" tabindex="-1"></a>a</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>tensor([[ 1.1171,  0.1585, -0.8696]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="80">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>torch.<span class="bu">sum</span>(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="80">
<pre><code>tensor(0.4060)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>More operations can be found in the <a href="https://pytorch.org/docs/stable/torch.html#torch-tensor-operations">Tensor Operations</a> section.</p>
</blockquote>
<section id="matrix-multiplication-is-all-you-need" class="level3">
<h3 class="anchored" data-anchor-id="matrix-multiplication-is-all-you-need">Matrix multiplication (is all you need)</h3>
<ul>
<li><p>One of the most common operations in machine learning and deep learning algorithms (like neural networks) is matrix multiplication.</p></li>
<li><p>PyTorch implements matrix multiplication functionality in the torch.matmul() method.</p></li>
<li><p>The main two rules for matrix multiplication to remember are:</p></li>
</ul>
<p>The inner dimensions must match:</p>
<ul>
<li>(3, 2) @ (3, 2) won’t work</li>
<li>(2, 3) @ (3, 2) will work</li>
<li>(3, 2) @ (2, 3) will work</li>
</ul>
<p>The resulting matrix has the shape of the outer dimensions:</p>
<ul>
<li>(2, 3) @ (3, 2) -&gt; (2, 2)</li>
<li>(3, 2) @ (2, 3) -&gt; (3, 3)</li>
</ul>
<p>Note: “@” in Python is the symbol for matrix multiplication.</p>
<p>More information about matrix multiplication can be found in the <a href="https://pytorch.org/docs/stable/torch.html#torch-matmul">Matrix Multiplication</a> section.</p>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb164"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>tensor1 <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a>tensor2 <span class="op">=</span> torch.randn(<span class="dv">4</span>)</span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor1.shape)</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor2.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 4])
torch.Size([4])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Can we multiply these tensors?</p>
</blockquote>
<div class="sourceCode cell-code" id="cb166"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> torch.matmul(tensor1, tensor2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="83">
<div class="sourceCode cell-code" id="cb167"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a>result</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="83">
<pre><code>tensor([ 9.1468,  4.9503, -1.1270])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>result.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="84">
<pre><code>torch.Size([3])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>The difference between element-wise multiplication (multiply) and matrix multiplication (matmul) is the addition of values.</p>
</blockquote>
<ul>
<li><p>matmul: matrix multiplication</p></li>
<li><p>multiply: element-wise multiplication</p></li>
</ul>
<div class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a>tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>torch.Size([3])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Element-wise matrix mutlication</span></span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">*</span> tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([1, 4, 9])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrix multiplication</span></span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor, tensor)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>tensor(14)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Can also use the "@" symbol for matrix multiplication, though not recommended</span></span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">@</span> tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>tensor(14)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>One of the most common errors in deep learning (shape errors)</p>
</blockquote>
<div class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Shapes need to be in the right way  </span></span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>tensor_A <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>],</span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">3</span>, <span class="dv">4</span>],</span>
<span id="cb179-4"><a href="#cb179-4" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">5</span>, <span class="dv">6</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb179-5"><a href="#cb179-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-6"><a href="#cb179-6" aria-hidden="true" tabindex="-1"></a>tensor_B <span class="op">=</span> torch.tensor([[<span class="dv">7</span>, <span class="dv">10</span>],</span>
<span id="cb179-7"><a href="#cb179-7" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">8</span>, <span class="dv">11</span>], </span>
<span id="cb179-8"><a href="#cb179-8" aria-hidden="true" tabindex="-1"></a>                         [<span class="dv">9</span>, <span class="dv">12</span>]], dtype<span class="op">=</span>torch.float32)</span>
<span id="cb179-9"><a href="#cb179-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb179-10"><a href="#cb179-10" aria-hidden="true" tabindex="-1"></a>torch.matmul(tensor_A, tensor_B) <span class="co"># (this will error)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A.shape)</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B.shape)</span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a><span class="co">#The shape of the tensor is not compatible with the shape of the matrix.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 2])
torch.Size([3, 2])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Solution !!! make matrix multiplication work between tensor_A and tensor_B by making their inner dimensions match using Transpose() operation.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb183"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View tensor_A and tensor_B</span></span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A)</span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.]])
tensor([[ 7., 10.],
        [ 8., 11.],
        [ 9., 12.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="co"># View tensor_A and tensor_B.T</span></span>
<span id="cb185-2"><a href="#cb185-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_A)</span>
<span id="cb185-3"><a href="#cb185-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor_B.T)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 2.],
        [3., 4.],
        [5., 6.]])
tensor([[ 7.,  8.,  9.],
        [10., 11., 12.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb187"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The operation works when tensor_B is transposed</span></span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Original shapes: tensor_A = </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">, tensor_B = </span><span class="sc">{</span>tensor_B<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb187-3"><a href="#cb187-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New shapes: tensor_A = </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> (same as above), tensor_B.T = </span><span class="sc">{</span>tensor_B<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb187-4"><a href="#cb187-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Multiplying: </span><span class="sc">{</span>tensor_A<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> * </span><span class="sc">{</span>tensor_B<span class="sc">.</span>T<span class="sc">.</span>shape<span class="sc">}</span><span class="ss"> &lt;- inner dimensions match</span><span class="ch">\n</span><span class="ss">"</span>)</span>
<span id="cb187-5"><a href="#cb187-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Output:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb187-6"><a href="#cb187-6" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> torch.matmul(tensor_A, tensor_B.T)</span>
<span id="cb187-7"><a href="#cb187-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(output) </span>
<span id="cb187-8"><a href="#cb187-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Output shape: </span><span class="sc">{</span>output<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])

New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 3])

Multiplying: torch.Size([3, 2]) * torch.Size([2, 3]) &lt;- inner dimensions match

Output:

tensor([[ 27.,  30.,  33.],
        [ 61.,  68.,  75.],
        [ 95., 106., 117.]])

Output shape: torch.Size([3, 3])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>You can also use torch.mm() which is a short for torch.matmul().</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a><span class="co"># torch.mm is a shortcut for matmul</span></span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>torch.mm(tensor_A, tensor_B.T)  <span class="co"># same as: torch.matmul(tensor_A, tensor_B.T)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="363">
<pre><code>tensor([[ 27.,  30.,  33.],
        [ 61.,  68.,  75.],
        [ 95., 106., 117.]])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: A matrix multiplication like this is also referred to as the dot product of two matrices. Neural networks are full of matrix multiplications and dot products.</p>
</blockquote>
<p>For example, <a href="https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html"><code>torch.nn.Linear()</code></a> module (we’ll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input <code>x</code> and a weights matrix <code>A</code>.</p>
<p><span class="math display">\[
y = x\cdot{A^T} + b
\]</span></p>
<section id="tensor-view-operation" class="level4">
<h4 class="anchored" data-anchor-id="tensor-view-operation">Tensor View Operation</h4>
<blockquote class="blockquote">
<p>Returns a new tensor with the same data as the self tensor but of a different shape.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">4</span>, <span class="dv">4</span>)</span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="374">
<pre><code>tensor([[ 0.2329, -1.1014, -1.2473, -0.7485],
        [-0.9792,  0.8285, -0.2501,  0.1602],
        [ 0.7295, -0.4441,  0.8214, -0.6015],
        [ 0.9069,  1.5691, -0.1108, -0.2573]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>x.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="375">
<pre><code>torch.Size([4, 4])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x.view(<span class="dv">16</span>)</span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a>y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="377">
<pre><code>tensor([ 0.2329, -1.1014, -1.2473, -0.7485, -0.9792,  0.8285, -0.2501,  0.1602,
         0.7295, -0.4441,  0.8214, -0.6015,  0.9069,  1.5691, -0.1108, -0.2573])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>y.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="378">
<pre><code>torch.Size([16])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Using -1 in the shape argument will automatically infer the correct size of the dimension.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span>)  <span class="co"># the size -1 is inferred from other dimensions</span></span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="379">
<pre><code>tensor([[ 0.2329, -1.1014, -1.2473, -0.7485, -0.9792,  0.8285, -0.2501,  0.1602],
        [ 0.7295, -0.4441,  0.8214, -0.6015,  0.9069,  1.5691, -0.1108, -0.2573]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>z.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="380">
<pre><code>torch.Size([2, 8])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>View Does not change tensor layout in memory</p>
</blockquote>
<p>Transpose() operation is used to change the tensor layout in memory.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a>a.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="381">
<pre><code>torch.Size([1, 2, 3, 4])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> a.transpose(<span class="dv">1</span>, <span class="dv">2</span>)  <span class="co"># Swaps 2nd and 3rd dimension</span></span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a>b.size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="382">
<pre><code>torch.Size([1, 3, 2, 4])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Tensor API provide group of operation on working with Tensors</p>
</blockquote>
</section>
</section>
</section>
<section id="tensors-and-computational-graphs" class="level2">
<h2 class="anchored" data-anchor-id="tensors-and-computational-graphs">Tensors and Computational Graphs</h2>
<ul>
<li><p>Tensor.requires_grad is a boolean flag that indicates whether the tensor requires gradient.</p></li>
<li><p>When you create a tensor with requires_grad=True, you are requiring PyTorch to manage bookkeeping information that computes gradients.</p></li>
<li><p>First, PyTorch will keep track of the values of the forward pass. Then, at the end of the computations, a single scalar is used to compute a backward pass.</p></li>
<li><p>The backward pass is initiated by using the backward() method on a tensor resulting from the evaluation of a loss function. The backward pass computes a gradient value for a tensor object that participated in the forward pass.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>) </span>
<span id="cb207-3"><a href="#cb207-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad <span class="kw">is</span> <span class="va">None</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn(<span class="dv">5</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x.<span class="bu">pow</span>(<span class="dv">2</span>)</span>
<span id="cb209-3"><a href="#cb209-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.equal(y.grad_fn._saved_self))  <span class="co"># True</span></span>
<span id="cb209-4"><a href="#cb209-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x <span class="kw">is</span> y.grad_fn._saved_self)  <span class="co"># True</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True
True</code></pre>
</div>
</div>
<ul>
<li>let’s run through a few ways to aggregate them (go from more values to less values).</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor</span></span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb211-3"><a href="#cb211-3" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="385">
<pre><code>tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Minimum: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb213-2"><a href="#cb213-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Maximum: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb213-3"><a href="#cb213-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">type</span>(torch.float32)<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># won't work without float datatype</span></span>
<span id="cb213-4"><a href="#cb213-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sum: </span><span class="sc">{</span>x<span class="sc">.</span><span class="bu">sum</span>()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Minimum: 0
Maximum: 90
Mean: 45.0
Sum: 450</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: You may find some methods such as torch.mean() require tensors to be in torch.float32 (the most common) or another specific datatype, otherwise the operation will fail.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb215"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Mean: </span><span class="sc">{</span>x<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>) <span class="co"># this will error</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long</code></pre>
</div>
</div>
<p>You can also do the same as above with torch methods.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb217"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.<span class="bu">max</span>(x))</span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.<span class="bu">min</span>(x))</span>
<span id="cb217-4"><a href="#cb217-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-5"><a href="#cb217-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.mean(x.<span class="bu">type</span>(torch.float32)))</span>
<span id="cb217-6"><a href="#cb217-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb217-7"><a href="#cb217-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.<span class="bu">sum</span>(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(90)
tensor(0)
tensor(45.)
tensor(450)</code></pre>
</div>
</div>
</section>
<section id="positional-minmax" class="level2">
<h2 class="anchored" data-anchor-id="positional-minmax">Positional min/max</h2>
<ul>
<li><p>You can also find the index of a tensor where the max or minimum occurs with torch.argmax() and torch.argmin() respectively.</p></li>
<li><p>This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we’ll see this in a later section when using the softmax activation function).</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor</span></span>
<span id="cb219-2"><a href="#cb219-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb219-3"><a href="#cb219-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Tensor: </span><span class="sc">{</span>tensor<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb219-4"><a href="#cb219-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb219-5"><a href="#cb219-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Returns index of max and min values</span></span>
<span id="cb219-6"><a href="#cb219-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Index where max value occurs: </span><span class="sc">{</span>tensor<span class="sc">.</span>argmax()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb219-7"><a href="#cb219-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Index where min value occurs: </span><span class="sc">{</span>tensor<span class="sc">.</span>argmin()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])
Index where max value occurs: 8
Index where min value occurs: 0</code></pre>
</div>
</div>
</section>
<section id="change-tensor-datatype" class="level2">
<h2 class="anchored" data-anchor-id="change-tensor-datatype">Change tensor datatype</h2>
<ul>
<li><p>A common issue with deep learning operations is having your tensors in different datatypes.</p></li>
<li><p>If one tensor is in torch.float64 and another is in torch.float32, you might run into some errors.</p></li>
<li><p>But there’s a fix.</p></li>
<li><p>You can change the datatypes of tensors using torch.Tensor.type(dtype=None) where the dtype parameter is the datatype you’d like to use</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb221"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb221-1"><a href="#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor and check its datatype</span></span>
<span id="cb221-2"><a href="#cb221-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.arange(<span class="fl">10.</span>, <span class="fl">100.</span>, <span class="fl">10.</span>)</span>
<span id="cb221-3"><a href="#cb221-3" aria-hidden="true" tabindex="-1"></a>tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="398">
<pre><code>torch.float32</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb223"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb223-1"><a href="#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a float16 tensor</span></span>
<span id="cb223-2"><a href="#cb223-2" aria-hidden="true" tabindex="-1"></a>tensor_float16 <span class="op">=</span> tensor.<span class="bu">type</span>(torch.float16)</span>
<span id="cb223-3"><a href="#cb223-3" aria-hidden="true" tabindex="-1"></a>tensor_float16</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="399">
<pre><code>tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb225"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a int8 tensor</span></span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a>tensor_int8 <span class="op">=</span> tensor.<span class="bu">type</span>(torch.int8)</span>
<span id="cb225-3"><a href="#cb225-3" aria-hidden="true" tabindex="-1"></a>tensor_int8</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="400">
<pre><code>tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)</code></pre>
</div>
</div>
<section id="reshaping-stacking-squeezing-and-unsqueezing" class="level3">
<h3 class="anchored" data-anchor-id="reshaping-stacking-squeezing-and-unsqueezing">Reshaping, stacking, squeezing and unsqueezing</h3>
<ul>
<li>Often times you’ll want to reshape or change the dimensions of your tensors without actually changing the values inside them.</li>
</ul>
<table class="table">
<thead>
<tr class="header">
<th>Method</th>
<th>One-line description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape"><code>torch.reshape(input, shape)</code></a></td>
<td>Reshapes <code>input</code> to <code>shape</code> (if compatible), can also use <code>torch.Tensor.reshape()</code>.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.Tensor.view.html"><code>torch.Tensor.view(shape)</code></a></td>
<td>Returns a view of the original tensor in a different <code>shape</code> but shares the same data as the original tensor.</td>
</tr>
<tr class="odd">
<td><a href="https://pytorch.org/docs/1.9.1/generated/torch.stack.html"><code>torch.stack(tensors, dim=0)</code></a></td>
<td>Concatenates a sequence of <code>tensors</code> along a new dimension (<code>dim</code>), all <code>tensors</code> must be same size.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.squeeze.html"><code>torch.squeeze(input)</code></a></td>
<td>Squeezes <code>input</code> to remove all the dimenions with value <code>1</code>.</td>
</tr>
<tr class="odd">
<td><a href="https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html"><code>torch.unsqueeze(input, dim)</code></a></td>
<td>Returns <code>input</code> with a dimension value of <code>1</code> added at <code>dim</code>.</td>
</tr>
<tr class="even">
<td><a href="https://pytorch.org/docs/stable/generated/torch.permute.html"><code>torch.permute(input, dims)</code></a></td>
<td>Returns a <em>view</em> of the original <code>input</code> with its dimensions permuted (rearranged) to <code>dims</code>.</td>
</tr>
</tbody>
</table>
<p>Why do any of these?</p>
<p>Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you’ve got shape mismatches, you’ll run into errors. These methods help you make the right elements of your tensors are mixing with the right elements of other tensors.</p>
<p>Let’s try them out.</p>
<p>First, we’ll create a tensor.</p>
<section id="reshape-and-view" class="level5">
<h5 class="anchored" data-anchor-id="reshape-and-view">Reshape and View</h5>
<div class="cell">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor</span></span>
<span id="cb227-2"><a href="#cb227-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb227-3"><a href="#cb227-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="fl">1.</span>, <span class="fl">8.</span>)</span>
<span id="cb227-4"><a href="#cb227-4" aria-hidden="true" tabindex="-1"></a>x, x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="401">
<pre><code>(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))</code></pre>
</div>
</div>
<p>Now let’s add an extra dimension with torch.reshape().</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb229"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add an extra dimension</span></span>
<span id="cb229-2"><a href="#cb229-2" aria-hidden="true" tabindex="-1"></a>x_reshaped <span class="op">=</span> x.reshape(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb229-3"><a href="#cb229-3" aria-hidden="true" tabindex="-1"></a>x_reshaped, x_reshaped.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="403">
<pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</code></pre>
</div>
</div>
<p>We can also change the view with torch.view().</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change view (keeps same data as original but changes view)</span></span>
<span id="cb231-2"><a href="#cb231-2" aria-hidden="true" tabindex="-1"></a><span class="co"># See more: https://stackoverflow.com/a/54507446/7900723</span></span>
<span id="cb231-3"><a href="#cb231-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x.view(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb231-4"><a href="#cb231-4" aria-hidden="true" tabindex="-1"></a>z, z.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="404">
<pre><code>(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))</code></pre>
</div>
</div>
</section>
<section id="torch.view-vs-torch.reshape" class="level5">
<h5 class="anchored" data-anchor-id="torch.view-vs-torch.reshape">Torch.View vs Torch.Reshape</h5>
<ul>
<li><p>Both view() and reshape() can be used to change the size or shape of tensors. But they are slightly different.</p></li>
<li><p>The view() has existed for a long time. It will return a tensor with the new shape. The returned tensor shares the underling data with the original tensor. If you change the tensor value in the returned tensor, the corresponding value in the viewed tensor also changes.</p></li>
<li><p>Tensor.reshape() is more robust. It will work on any tensor, while Tensor.view() works only on tensor t where t.is_contiguous()==True.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.zeros(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb233-2"><a href="#cb233-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> z.view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb233-3"><a href="#cb233-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb233-4"><a href="#cb233-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span>
<span id="cb233-5"><a href="#cb233-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0., 0.],
        [0., 0.],
        [0., 0.]])
tensor([[0., 0., 0.],
        [0., 0., 0.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>z.fill_(<span class="dv">1</span>)</span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-3"><a href="#cb235-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb235-4"><a href="#cb235-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span>
<span id="cb235-5"><a href="#cb235-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[1., 1.],
        [1., 1.],
        [1., 1.]])
tensor([[1., 1., 1.],
        [1., 1., 1.]])</code></pre>
</div>
</div>
<p>According to <a href="https://pytorch.org/docs/master/generated/torch.reshape.html#torch.reshape">documentation</a></p>
<blockquote class="blockquote">
<p>Reshape() Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs.&nbsp;viewing behavior.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.arange(<span class="fl">4.</span>)</span>
<span id="cb237-2"><a href="#cb237-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb237-3"><a href="#cb237-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.reshape(a, (<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb237-4"><a href="#cb237-4" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="437">
<pre><code>tensor([[0., 1.],
        [2., 3.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>a.fill_(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="438">
<pre><code>tensor([2., 2., 2., 2.])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>z</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="436">
<pre><code>tensor([[2., 2.],
        [2., 2.]])</code></pre>
</div>
</div>
<p>More about reshape vs view <a href="https://discuss.pytorch.org/t/equivalent-of-np-reshape-in-pytorch/144/16">here</a> , <a href="https://jdhao.github.io/2019/07/10/pytorch_view_reshape_transpose_permute/">here</a></p>
</section>
</section>
<section id="stack-tensor" class="level3">
<h3 class="anchored" data-anchor-id="stack-tensor">Stack Tensor</h3>
<ul>
<li><p>If we wanted to stack our new tensor on top of itself five times, we could do so with torch.stack().</p></li>
<li><p>Concatenates a sequence of tensors along a new dimension.</p></li>
<li><p>All tensors need to be of the same size.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="co"># creating tensors</span></span>
<span id="cb243-2"><a href="#cb243-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.</span>,<span class="fl">3.</span>,<span class="fl">6.</span>,<span class="fl">10.</span>])</span>
<span id="cb243-3"><a href="#cb243-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.tensor([<span class="fl">2.</span>,<span class="fl">7.</span>,<span class="fl">9.</span>,<span class="fl">13.</span>])</span>
<span id="cb243-4"><a href="#cb243-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb243-5"><a href="#cb243-5" aria-hidden="true" tabindex="-1"></a><span class="co"># printing above created tensors</span></span>
<span id="cb243-6"><a href="#cb243-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tensor x:"</span>, x)</span>
<span id="cb243-7"><a href="#cb243-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Tensor y:"</span>, y)</span>
<span id="cb243-8"><a href="#cb243-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb243-9"><a href="#cb243-9" aria-hidden="true" tabindex="-1"></a><span class="co"># join above tensor using "torch.stack()"</span></span>
<span id="cb243-10"><a href="#cb243-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"join tensors:"</span>)</span>
<span id="cb243-11"><a href="#cb243-11" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.stack((x,y))</span>
<span id="cb243-12"><a href="#cb243-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb243-13"><a href="#cb243-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print final tensor after join</span></span>
<span id="cb243-14"><a href="#cb243-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t)</span>
<span id="cb243-15"><a href="#cb243-15" aria-hidden="true" tabindex="-1"></a>  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tensor x: tensor([ 1.,  3.,  6., 10.])
Tensor y: tensor([ 2.,  7.,  9., 13.])
join tensors:
tensor([[ 1.,  3.,  6., 10.],
        [ 2.,  7.,  9., 13.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"join tensors dimension 0:"</span>)</span>
<span id="cb245-2"><a href="#cb245-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.stack((x,y), dim <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb245-3"><a href="#cb245-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>join tensors dimension 0:
tensor([[ 1.,  3.,  6., 10.],
        [ 2.,  7.,  9., 13.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"join tensors dimension 1:"</span>)</span>
<span id="cb247-2"><a href="#cb247-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.stack((x,y), dim <span class="op">=</span> <span class="dv">1</span>)</span>
<span id="cb247-3"><a href="#cb247-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>join tensors dimension 1:
tensor([[ 1.,  2.],
        [ 3.,  7.],
        [ 6.,  9.],
        [10., 13.]])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>When dim =0 the tensors are stacked increasing the number of rows. When dim =1 the tensors are transposed and stacked along the column.</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb249"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Stack tensors on top of each other</span></span>
<span id="cb249-2"><a href="#cb249-2" aria-hidden="true" tabindex="-1"></a>torch.stack((x,y), dim <span class="op">=</span> <span class="dv">1</span>).size()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="467">
<pre><code>torch.Size([4, 2])</code></pre>
</div>
</div>
</section>
<section id="adding-and-removinga-single-dimension-squeeze-and-unsqueeze" class="level3">
<h3 class="anchored" data-anchor-id="adding-and-removinga-single-dimension-squeeze-and-unsqueeze">Adding and Removinga single dimension ( Squeeze and Unsqueeze))</h3>
<ul>
<li>Simply put, unsqueeze() “adds” a superficial 1 dimension to tensor (at the specified dimension), while squeeze removes all superficial 1 dimensions from tensor.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb251"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>])</span>
<span id="cb251-2"><a href="#cb251-2" aria-hidden="true" tabindex="-1"></a>tensor.shape <span class="co"># torch.Size([5])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="476">
<pre><code>torch.Size([5])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>).shape <span class="co"># [1, 5]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="477">
<pre><code>torch.Size([1, 5])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb255"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb255-1"><a href="#cb255-1" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>).shape <span class="co"># [5, 1]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="478">
<pre><code>torch.Size([5, 1])</code></pre>
</div>
</div>
<p>It is useful for providing single sample to the network (which requires first dimension to be batch), for images it would be:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 channels, 32 width, 32 height</span></span>
<span id="cb257-2"><a href="#cb257-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb257-3"><a href="#cb257-3" aria-hidden="true" tabindex="-1"></a>tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="473">
<pre><code>torch.Size([3, 32, 32])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb259"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1 batch, 3 channels, 32 width, 32 height</span></span>
<span id="cb259-2"><a href="#cb259-2" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="474">
<pre><code>torch.Size([1, 3, 32, 32])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb261"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb261-1"><a href="#cb261-1" aria-hidden="true" tabindex="-1"></a>tensor.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="475">
<pre><code>torch.Size([3, 1, 32, 32])</code></pre>
</div>
</div>
<ul>
<li>Squeeze() removes the dimension of size 1 from the tensor.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 channels, 32 width, 32 height</span></span>
<span id="cb263-2"><a href="#cb263-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.randn(<span class="dv">3</span>, <span class="dv">32</span>, <span class="dv">32</span>)</span>
<span id="cb263-3"><a href="#cb263-3" aria-hidden="true" tabindex="-1"></a>squeezed_tensor <span class="op">=</span> tensor.unsqueeze(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb263-4"><a href="#cb263-4" aria-hidden="true" tabindex="-1"></a>squeezed_tensor.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="493">
<pre><code>torch.Size([1, 3, 32, 32])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb265"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a>squeezed_tensor.squeeze().shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="497">
<pre><code>torch.Size([3, 32, 32])</code></pre>
</div>
</div>
</section>
<section id="permute-tensor" class="level3">
<h3 class="anchored" data-anchor-id="permute-tensor">Permute Tensor</h3>
<ul>
<li>You can also rearrange the order of axes values with torch.permute(input, dims), where the input gets turned into a view with new dims.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb267"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb267-1"><a href="#cb267-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tensor with specific shape</span></span>
<span id="cb267-2"><a href="#cb267-2" aria-hidden="true" tabindex="-1"></a>x_original <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">224</span>, <span class="dv">224</span>, <span class="dv">3</span>))</span>
<span id="cb267-3"><a href="#cb267-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-4"><a href="#cb267-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Permute the original tensor to rearrange the axis order</span></span>
<span id="cb267-5"><a href="#cb267-5" aria-hidden="true" tabindex="-1"></a>x_permuted <span class="op">=</span> x_original.permute(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">1</span>) <span class="co"># shifts axis 0-&gt;1, 1-&gt;2, 2-&gt;0</span></span>
<span id="cb267-6"><a href="#cb267-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb267-7"><a href="#cb267-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Previous shape: </span><span class="sc">{</span>x_original<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb267-8"><a href="#cb267-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"New shape: </span><span class="sc">{</span>x_permuted<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Previous shape: torch.Size([224, 224, 3])
New shape: torch.Size([3, 224, 224])</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: Because permuting returns a view (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original.</p>
</blockquote>
</section>
</section>
<section id="indexing-selecting-data-from-tensors" class="level2">
<h2 class="anchored" data-anchor-id="indexing-selecting-data-from-tensors">Indexing (selecting data from tensors)</h2>
<ul>
<li><p>Indexing allow us to select data from tensors(e.g, select the first row of a tensor).</p></li>
<li><p>Indexing a Pytorch tensor is similar to that of a Python list. The pytorch tensor indexing is 0 based, i.e, the first element of the array has index 0.</p></li>
<li><p>Syntax : tensor_name[index]</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb269"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb269-1"><a href="#cb269-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">9</span>])</span>
<span id="cb269-2"><a href="#cb269-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb269-3"><a href="#cb269-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">0</span>])</span>
<span id="cb269-4"><a href="#cb269-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">3</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(2)
tensor(7)</code></pre>
</div>
</div>
<p>Indexing Range : tensor_name[start_index : end_index]</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb271"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb271-1"><a href="#cb271-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">9</span>])</span>
<span id="cb271-2"><a href="#cb271-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb271-3"><a href="#cb271-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">1</span> : <span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([4, 1, 7, 0])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb273"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">9</span>])</span>
<span id="cb273-2"><a href="#cb273-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">2</span> : ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 7, 0, 9])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">4</span>]])</span>
<span id="cb275-2"><a href="#cb275-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb275-3"><a href="#cb275-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">1</span>])</span>
<span id="cb275-4"><a href="#cb275-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([3, 8, 4])
tensor([1, 2, 1])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb277"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>], [<span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">4</span>]])</span>
<span id="cb277-2"><a href="#cb277-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb277-3"><a href="#cb277-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor[<span class="dv">0</span>][<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor(2)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb279"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a tensor </span></span>
<span id="cb279-2"><a href="#cb279-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb279-3"><a href="#cb279-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">1</span>, <span class="dv">10</span>).reshape(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb279-4"><a href="#cb279-4" aria-hidden="true" tabindex="-1"></a>x, x.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="499">
<pre><code>(tensor([[[1, 2, 3],
          [4, 5, 6],
          [7, 8, 9]]]),
 torch.Size([1, 3, 3]))</code></pre>
</div>
</div>
<p>Indexing values goes outer dimension -&gt; inner dimension (check out the square brackets).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb281"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let's index bracket by bracket</span></span>
<span id="cb281-2"><a href="#cb281-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"First square bracket:</span><span class="ch">\n</span><span class="sc">{</span>x[<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb281-3"><a href="#cb281-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Second square bracket: </span><span class="sc">{</span>x[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>) </span>
<span id="cb281-4"><a href="#cb281-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Third square bracket: </span><span class="sc">{</span>x[<span class="dv">0</span>][<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>First square bracket:
tensor([[1, 2, 3],
        [4, 5, 6],
        [7, 8, 9]])
Second square bracket: tensor([1, 2, 3])
Third square bracket: 1</code></pre>
</div>
</div>
<section id="pytorch-tensors-numpy" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-tensors-numpy">PyTorch tensors &amp; NumPy</h3>
<ul>
<li><p>Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.</p></li>
<li><p>The two main methods you’ll want to use for NumPy to PyTorch (and back again) are:</p>
<ul>
<li>torch.from_numpy(ndarray) - NumPy array -&gt; PyTorch tensor.</li>
<li>torch.Tensor.numpy() - PyTorch tensor -&gt; NumPy array.</li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="co"># NumPy array to tensor</span></span>
<span id="cb283-2"><a href="#cb283-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb283-3"><a href="#cb283-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb283-4"><a href="#cb283-4" aria-hidden="true" tabindex="-1"></a>array <span class="op">=</span> np.arange(<span class="fl">1.0</span>, <span class="fl">8.0</span>)</span>
<span id="cb283-5"><a href="#cb283-5" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.from_numpy(array)</span>
<span id="cb283-6"><a href="#cb283-6" aria-hidden="true" tabindex="-1"></a>array, tensor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="513">
<pre><code>(array([1., 2., 3., 4., 5., 6., 7.]),
 tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Note: By default, NumPy arrays are created with the datatype float64 and if you convert it to a PyTorch tensor, it’ll keep the same datatype (as above). However, many PyTorch calculations default to using float32. So if you want to convert your NumPy array (float64) -&gt; PyTorch tensor (float64) -&gt; PyTorch tensor (float32), you can use tensor = torch.from_numpy(array).type(torch.float32).</p>
</blockquote>
<div class="cell">
<div class="sourceCode cell-code" id="cb285"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.from_numpy(array).<span class="bu">type</span>(torch.float32)</span>
<span id="cb285-2"><a href="#cb285-2" aria-hidden="true" tabindex="-1"></a>tensor.dtype</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="519">
<pre><code>torch.float32</code></pre>
</div>
</div>
</section>
<section id="running-tensors-on-gpus-and-making-faster-computations" class="level3">
<h3 class="anchored" data-anchor-id="running-tensors-on-gpus-and-making-faster-computations">Running tensors on GPUs (and making faster computations)</h3>
<ul>
<li><p>Deep learning algorithms require a lot of numerical operations.</p></li>
<li><p>However, there’s another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.</p></li>
</ul>
<p><img src="./GPU.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>How can I get GPU?</p>
</blockquote>
<ul>
<li><p>Buy Hardware, NVIDVIA. Guide for buying <a href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">GPU</a></p></li>
<li><p>Cloud computing (AWS, GCP, Azure etc)</p></li>
<li><p>Free: Colab, Kaggle,</p></li>
</ul>
<section id="cuda" class="level5">
<h5 class="anchored" data-anchor-id="cuda">CUDA</h5>
<div class="cell">
<div class="sourceCode cell-code" id="cb287"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check if CUDA is available</span></span>
<span id="cb287-2"><a href="#cb287-2" aria-hidden="true" tabindex="-1"></a>torch.cuda.is_available()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="523">
<pre><code>False</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb289"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb289-1"><a href="#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Set device type</span></span>
<span id="cb289-2"><a href="#cb289-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb289-3"><a href="#cb289-3" aria-hidden="true" tabindex="-1"></a>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="524">
<pre><code>'cpu'</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb291"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a>torch.cuda.device_count() <span class="co"># count number of GPUs</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="529">
<pre><code>0</code></pre>
</div>
</div>
</section>
<section id="mps-apple-metal-performance-shaders-mps-as-the-backend-for-pytorch" class="level4">
<h4 class="anchored" data-anchor-id="mps-apple-metal-performance-shaders-mps-as-the-backend-for-pytorch">MPS : Apple’ Metal Performance Shaders (MPS) as the backend for PyTorch</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check PyTorch has access to MPS (Metal Performance Shader, Apple's GPU architecture)</span></span>
<span id="cb293-2"><a href="#cb293-2" aria-hidden="true" tabindex="-1"></a>torch.backends.mps.is_available()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="526">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the device      </span></span>
<span id="cb295-3"><a href="#cb295-3" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"mps"</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb295-4"><a href="#cb295-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Using device: mps</code></pre>
</div>
</div>
</section>
</section>
<section id="putting-tensors-and-models-on-the-gpu" class="level3">
<h3 class="anchored" data-anchor-id="putting-tensors-and-models-on-the-gpu">Putting tensors (and models) on the GPU</h3>
<ul>
<li>You can put tensors (and models, we’ll see this later) on a specific device by calling to(device) on them.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb297"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-3"><a href="#cb297-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the device</span></span>
<span id="cb297-4"><a href="#cb297-4" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"mps"</span> <span class="cf">if</span> torch.backends.mps.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb297-5"><a href="#cb297-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb297-6"><a href="#cb297-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data and send it to the device</span></span>
<span id="cb297-7"><a href="#cb297-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(size<span class="op">=</span>(<span class="dv">3</span>, <span class="dv">4</span>)).to(device)</span>
<span id="cb297-8"><a href="#cb297-8" aria-hidden="true" tabindex="-1"></a>x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="539">
<pre><code>tensor([[0.8095, 0.0784, 0.3189, 0.0733],
        [0.7410, 0.3840, 0.9461, 0.1013],
        [0.1974, 0.8245, 0.5863, 0.9017]], device='mps:0')</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb299"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create tensor (default on CPU)</span></span>
<span id="cb299-2"><a href="#cb299-2" aria-hidden="true" tabindex="-1"></a>tensor <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>])</span>
<span id="cb299-3"><a href="#cb299-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb299-4"><a href="#cb299-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Tensor not on GPU</span></span>
<span id="cb299-5"><a href="#cb299-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tensor, tensor.device)</span>
<span id="cb299-6"><a href="#cb299-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb299-7"><a href="#cb299-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Move tensor to GPU (if available)</span></span>
<span id="cb299-8"><a href="#cb299-8" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu <span class="op">=</span> tensor.to(device)</span>
<span id="cb299-9"><a href="#cb299-9" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([1, 2, 3]) cpu</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="540">
<pre><code>tensor([1, 2, 3], device='mps:0')</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>Notice the second tensor has device=‘mps:0’, this means it’s stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they’d be ‘mps:0’ and ‘cuda:1’ respectively, up to ‘cuda:n’).</p>
</blockquote>
</section>
<section id="moving-tensors-back-to-the-cpu" class="level3">
<h3 class="anchored" data-anchor-id="moving-tensors-back-to-the-cpu">Moving tensors back to the CPU¶</h3>
<ul>
<li><p>We will use the .to(‘cpu’) method to move tensors back to the CPU.</p></li>
<li><p>If this object is already in CPU memory and on the correct device, then no copy is performed and the original object is returned.</p></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb302"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a>tensor_on_gpu <span class="co">#on GPU</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="543">
<pre><code>tensor([1, 2, 3], device='mps:0')</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb304"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instead, copy the tensor back to cpu</span></span>
<span id="cb304-2"><a href="#cb304-2" aria-hidden="true" tabindex="-1"></a>tensor_back_on_cpu <span class="op">=</span> tensor_on_gpu.cpu()</span>
<span id="cb304-3"><a href="#cb304-3" aria-hidden="true" tabindex="-1"></a>tensor_back_on_cpu</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="542">
<pre><code>tensor([1, 2, 3])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb306"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb306-1"><a href="#cb306-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instead, copy the tensor back to cpu</span></span>
<span id="cb306-2"><a href="#cb306-2" aria-hidden="true" tabindex="-1"></a>tensor_back_to_numpy <span class="op">=</span> tensor_on_gpu.cpu().numpy()</span>
<span id="cb306-3"><a href="#cb306-3" aria-hidden="true" tabindex="-1"></a>tensor_back_to_numpy</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="544">
<pre><code>array([1, 2, 3])</code></pre>
</div>
</div>
</section>
</section>
<section id="more-on-tensors" class="level2">
<h2 class="anchored" data-anchor-id="more-on-tensors">More on Tensors</h2>
<ul>
<li><p>Pytorch Beginner Tutorial <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">here</a>. This is a great tutorial for learning about Pytorch. Quickstart and Tensor Sections !</p></li>
<li><p>Learn more about Tensor representations <a href="https://www.youtube.com/watch?v=f5liqUk0ZTw&amp;ab_channel=DanFleisch">here</a></p></li>
</ul>
</section>
<section id="exercises" class="level2">
<h2 class="anchored" data-anchor-id="exercises">Exercises</h2>
<p>The best way to master a topic is to solve problems. Here are some warm­up exercises. Many of the problems will require going through the official ocumentation and finding helpful functions.</p>
</section>
<section id="finding-the-min-max-mean-sum-etc-aggregation" class="level2">
<h2 class="anchored" data-anchor-id="finding-the-min-max-mean-sum-etc-aggregation">Finding the min, max, mean, sum, etc (aggregation)¶</h2>
<p>1 Create a 2D tensor and then add a dimension of size 1 inserted at dimension 0.</p>
<ol start="2" type="1">
<li><p>Remove the extra dimension you just added to the previous tensor.</p></li>
<li><p>Create a random tensor of shape 5x3 in the interval [3, 7)</p></li>
<li><p>Create a tensor with values from a normal distribution (mean=0, std=1).</p></li>
<li><p>Retrieve the indexes of all the nonzero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).</p></li>
<li><p>Create a random tensor of size (3,1) and then horizontally stack four copies together.</p></li>
<li><p>Return the batch matrix­matrix product of two three­dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).</p></li>
<li><p>Return the batch matrix­matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4))</p></li>
</ol>
</section>
<section id="indexing-slicing-and-joining" class="level2">
<h2 class="anchored" data-anchor-id="indexing-slicing-and-joining">Indexing, Slicing, and Joining</h2>
<ul>
<li>PyTorch’s indexing and slicing is similar to NumPy’s.</li>
</ul>
<section id="special-tensor-initializations" class="level3">
<h3 class="anchored" data-anchor-id="special-tensor-initializations">Special Tensor initializations</h3>
<p>We can create a vector of incremental numbers</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb308"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb308-1"><a href="#cb308-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb308-2"><a href="#cb308-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
<p>Sometimes it’s useful to have an integer-based arange for indexing</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb310"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">10</span>).<span class="bu">long</span>()</span>
<span id="cb310-2"><a href="#cb310-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])</code></pre>
</div>
</div>
</section>
</section>
<section id="operations" class="level2">
<h2 class="anchored" data-anchor-id="operations">Operations</h2>
<p>Using the tensors to do linear algebra is a foundation of modern Deep Learning practices</p>
<p>Reshaping allows you to move the numbers in a tensor around. One can be sure that the order is preserved. In PyTorch, reshaping is called <code>view</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb312"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb312-1"><a href="#cb312-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">20</span>)</span>
<span id="cb312-2"><a href="#cb312-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb312-3"><a href="#cb312-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">1</span>, <span class="dv">20</span>))</span>
<span id="cb312-4"><a href="#cb312-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">2</span>, <span class="dv">10</span>))</span>
<span id="cb312-5"><a href="#cb312-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">4</span>, <span class="dv">5</span>))</span>
<span id="cb312-6"><a href="#cb312-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">5</span>, <span class="dv">4</span>))</span>
<span id="cb312-7"><a href="#cb312-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">10</span>, <span class="dv">2</span>))</span>
<span id="cb312-8"><a href="#cb312-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.view(<span class="dv">20</span>, <span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19]])
tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],
        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])
tensor([[ 0,  1,  2,  3,  4],
        [ 5,  6,  7,  8,  9],
        [10, 11, 12, 13, 14],
        [15, 16, 17, 18, 19]])
tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11],
        [12, 13, 14, 15],
        [16, 17, 18, 19]])
tensor([[ 0,  1],
        [ 2,  3],
        [ 4,  5],
        [ 6,  7],
        [ 8,  9],
        [10, 11],
        [12, 13],
        [14, 15],
        [16, 17],
        [18, 19]])
tensor([[ 0],
        [ 1],
        [ 2],
        [ 3],
        [ 4],
        [ 5],
        [ 6],
        [ 7],
        [ 8],
        [ 9],
        [10],
        [11],
        [12],
        [13],
        [14],
        [15],
        [16],
        [17],
        [18],
        [19]])</code></pre>
</div>
</div>
<p>We can use view to add size-1 dimensions, which can be useful for combining with other tensors. This is called broadcasting.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb314"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb314-2"><a href="#cb314-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.arange(<span class="dv">4</span>).view(<span class="dv">1</span>, <span class="dv">4</span>)</span>
<span id="cb314-3"><a href="#cb314-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.arange(<span class="dv">3</span>).view(<span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb314-4"><a href="#cb314-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb314-5"><a href="#cb314-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb314-6"><a href="#cb314-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(y)</span>
<span id="cb314-7"><a href="#cb314-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span>
<span id="cb314-8"><a href="#cb314-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x <span class="op">+</span> y)</span>
<span id="cb314-9"><a href="#cb314-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x <span class="op">+</span> z)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
tensor([[0, 1, 2, 3]])
tensor([[0],
        [1],
        [2]])
tensor([[ 0,  2,  4,  6],
        [ 4,  6,  8, 10],
        [ 8, 10, 12, 14]])
tensor([[ 0,  1,  2,  3],
        [ 5,  6,  7,  8],
        [10, 11, 12, 13]])</code></pre>
</div>
</div>
<p>Unsqueeze and squeeze will add and remove 1-dimensions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb316"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).view(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb316-2"><a href="#cb316-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span>
<span id="cb316-3"><a href="#cb316-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb316-4"><a href="#cb316-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.unsqueeze(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb316-5"><a href="#cb316-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span>
<span id="cb316-6"><a href="#cb316-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb316-7"><a href="#cb316-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.squeeze()</span>
<span id="cb316-8"><a href="#cb316-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([3, 4])
torch.Size([3, 1, 4])
torch.Size([3, 4])</code></pre>
</div>
</div>
<p>all of the standard mathematics operations apply (such as <code>add</code> below)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb318"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb318-1"><a href="#cb318-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb318-2"><a href="#cb318-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb318-3"><a href="#cb318-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span>)</span>
<span id="cb318-4"><a href="#cb318-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"torch.add(x, x): </span><span class="ch">\n</span><span class="st">"</span>, torch.add(x, x))</span>
<span id="cb318-5"><a href="#cb318-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--"</span>)</span>
<span id="cb318-6"><a href="#cb318-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x+x: </span><span class="ch">\n</span><span class="st">"</span>, x <span class="op">+</span> x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[0.6662, 0.3343, 0.7893, 0.3216],
        [0.5247, 0.6688, 0.8436, 0.4265],
        [0.9561, 0.0770, 0.4108, 0.0014]])
--
torch.add(x, x): 
 tensor([[1.3324, 0.6686, 1.5786, 0.6433],
        [1.0494, 1.3377, 1.6872, 0.8530],
        [1.9123, 0.1540, 0.8216, 0.0028]])
--
x+x: 
 tensor([[1.3324, 0.6686, 1.5786, 0.6433],
        [1.0494, 1.3377, 1.6872, 0.8530],
        [1.9123, 0.1540, 0.8216, 0.0028]])</code></pre>
</div>
</div>
<p>The convention of <code>_</code> indicating in-place operations continues:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb320"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).reshape(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb320-2"><a href="#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb320-3"><a href="#cb320-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.add_(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
tensor([[ 0,  2,  4,  6],
        [ 8, 10, 12, 14],
        [16, 18, 20, 22]])</code></pre>
</div>
</div>
<p>There are many operations for which reduce a dimension. Such as sum:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb322"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">12</span>).reshape(<span class="dv">3</span>, <span class="dv">4</span>)</span>
<span id="cb322-2"><a href="#cb322-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb322-3"><a href="#cb322-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb322-4"><a href="#cb322-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Summing across rows (dim=0): </span><span class="ch">\n</span><span class="st">"</span>, x.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb322-5"><a href="#cb322-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb322-6"><a href="#cb322-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Summing across columns (dim=1): </span><span class="ch">\n</span><span class="st">"</span>, x.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
---
Summing across rows (dim=0): 
 tensor([12, 15, 18, 21])
---
Summing across columns (dim=1): 
 tensor([ 6, 22, 38])</code></pre>
</div>
</div>
<section id="indexing-slicing-joining-and-mutating" class="level4">
<h4 class="anchored" data-anchor-id="indexing-slicing-joining-and-mutating">Indexing, Slicing, Joining and Mutating</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb324"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb324-2"><a href="#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb324-3"><a href="#cb324-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb324-4"><a href="#cb324-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x[:2, :2]: </span><span class="ch">\n</span><span class="st">"</span>, x[:<span class="dv">2</span>, :<span class="dv">2</span>])</span>
<span id="cb324-5"><a href="#cb324-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb324-6"><a href="#cb324-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x[0][1]: </span><span class="ch">\n</span><span class="st">"</span>, x[<span class="dv">0</span>][<span class="dv">1</span>])</span>
<span id="cb324-7"><a href="#cb324-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb324-8"><a href="#cb324-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Setting [0][1] to be 8"</span>)</span>
<span id="cb324-9"><a href="#cb324-9" aria-hidden="true" tabindex="-1"></a>x[<span class="dv">0</span>][<span class="dv">1</span>] <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb324-10"><a href="#cb324-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[0, 1, 2],
        [3, 4, 5]])
---
x[:2, :2]: 
 tensor([[0, 1],
        [3, 4]])
---
x[0][1]: 
 tensor(1)
---
Setting [0][1] to be 8
tensor([[0, 8, 2],
        [3, 4, 5]])</code></pre>
</div>
</div>
<p>We can select a subset of a tensor using the <code>index_select</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb326"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb326-2"><a href="#cb326-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb326-3"><a href="#cb326-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-4"><a href="#cb326-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb326-5"><a href="#cb326-5" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.LongTensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb326-6"><a href="#cb326-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.index_select(x, dim<span class="op">=</span><span class="dv">0</span>, index<span class="op">=</span>indices))</span>
<span id="cb326-7"><a href="#cb326-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-8"><a href="#cb326-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb326-9"><a href="#cb326-9" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.LongTensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb326-10"><a href="#cb326-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.index_select(x, dim<span class="op">=</span><span class="dv">1</span>, index<span class="op">=</span>indices))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
---
tensor([[0, 1, 2],
        [6, 7, 8]])
---
tensor([[0, 2],
        [3, 5],
        [6, 8]])</code></pre>
</div>
</div>
<p>We can also use numpy-style advanced indexing:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb328"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> torch.LongTensor([<span class="dv">0</span>, <span class="dv">2</span>])</span>
<span id="cb328-3"><a href="#cb328-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb328-4"><a href="#cb328-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x[indices])</span>
<span id="cb328-5"><a href="#cb328-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb328-6"><a href="#cb328-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x[indices, :])</span>
<span id="cb328-7"><a href="#cb328-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb328-8"><a href="#cb328-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x[:, indices])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [6, 7, 8]])
---
tensor([[0, 1, 2],
        [6, 7, 8]])
---
tensor([[0, 2],
        [3, 5],
        [6, 8]])</code></pre>
</div>
</div>
<p>We can combine tensors by concatenating them. First, concatenating on the rows</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb330"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb330-1"><a href="#cb330-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb330-2"><a href="#cb330-2" aria-hidden="true" tabindex="-1"></a>describe(x)</span>
<span id="cb330-3"><a href="#cb330-3" aria-hidden="true" tabindex="-1"></a>describe(torch.cat([x, x], dim<span class="op">=</span><span class="dv">0</span>))</span>
<span id="cb330-4"><a href="#cb330-4" aria-hidden="true" tabindex="-1"></a>describe(torch.cat([x, x], dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb330-5"><a href="#cb330-5" aria-hidden="true" tabindex="-1"></a>describe(torch.stack([x, x]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.LongTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5]])
Type: torch.LongTensor
Shape/size: torch.Size([4, 3])
Values: 
tensor([[0, 1, 2],
        [3, 4, 5],
        [0, 1, 2],
        [3, 4, 5]])
Type: torch.LongTensor
Shape/size: torch.Size([2, 6])
Values: 
tensor([[0, 1, 2, 0, 1, 2],
        [3, 4, 5, 3, 4, 5]])
Type: torch.LongTensor
Shape/size: torch.Size([2, 2, 3])
Values: 
tensor([[[0, 1, 2],
         [3, 4, 5]],

        [[0, 1, 2],
         [3, 4, 5]]])</code></pre>
</div>
</div>
<p>We can concentate along the first dimension.. the columns.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb332"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb332-1"><a href="#cb332-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb332-2"><a href="#cb332-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb332-3"><a href="#cb332-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb332-4"><a href="#cb332-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb332-5"><a href="#cb332-5" aria-hidden="true" tabindex="-1"></a>new_x <span class="op">=</span> torch.cat([x, x, x], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb332-6"><a href="#cb332-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x.shape)</span>
<span id="cb332-7"><a href="#cb332-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
---
torch.Size([3, 9])
tensor([[0, 1, 2, 0, 1, 2, 0, 1, 2],
        [3, 4, 5, 3, 4, 5, 3, 4, 5],
        [6, 7, 8, 6, 7, 8, 6, 7, 8]])</code></pre>
</div>
</div>
<p>We can also concatenate on a new 0th dimension to “stack” the tensors:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb334"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb334-1"><a href="#cb334-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">9</span>).view(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb334-2"><a href="#cb334-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb334-3"><a href="#cb334-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb334-4"><a href="#cb334-4" aria-hidden="true" tabindex="-1"></a>new_x <span class="op">=</span> torch.stack([x, x, x])</span>
<span id="cb334-5"><a href="#cb334-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x.shape)</span>
<span id="cb334-6"><a href="#cb334-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(new_x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0, 1, 2],
        [3, 4, 5],
        [6, 7, 8]])
---
torch.Size([3, 3, 3])
tensor([[[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]],

        [[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]],

        [[0, 1, 2],
         [3, 4, 5],
         [6, 7, 8]]])</code></pre>
</div>
</div>
</section>
<section id="linear-algebra-tensor-functions" class="level4">
<h4 class="anchored" data-anchor-id="linear-algebra-tensor-functions">Linear Algebra Tensor Functions</h4>
<p>Transposing allows you to switch the dimensions to be on different axis. So we can make it so all the rows are columsn and vice versa.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb336"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">12</span>).view(<span class="dv">3</span>,<span class="dv">4</span>)</span>
<span id="cb336-2"><a href="#cb336-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x) </span>
<span id="cb336-3"><a href="#cb336-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb336-4"><a href="#cb336-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.tranpose(1, 0): </span><span class="ch">\n</span><span class="st">"</span>, x.transpose(<span class="dv">1</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[ 0,  1,  2,  3],
        [ 4,  5,  6,  7],
        [ 8,  9, 10, 11]])
---
x.tranpose(1, 0): 
 tensor([[ 0,  4,  8],
        [ 1,  5,  9],
        [ 2,  6, 10],
        [ 3,  7, 11]])</code></pre>
</div>
</div>
<p>A three dimensional tensor would represent a batch of sequences, where each sequence item has a feature vector. It is common to switch the batch and sequence dimensions so that we can more easily index the sequence in a sequence model.</p>
<p>Note: Transpose will only let you swap 2 axes. Permute (in the next cell) allows for multiple</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb338"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb338-1"><a href="#cb338-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb338-2"><a href="#cb338-2" aria-hidden="true" tabindex="-1"></a>seq_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb338-3"><a href="#cb338-3" aria-hidden="true" tabindex="-1"></a>feature_size <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb338-4"><a href="#cb338-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb338-5"><a href="#cb338-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(batch_size <span class="op">*</span> seq_size <span class="op">*</span> feature_size).view(batch_size, seq_size, feature_size)</span>
<span id="cb338-6"><a href="#cb338-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb338-7"><a href="#cb338-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.shape: </span><span class="ch">\n</span><span class="st">"</span>, x.shape)</span>
<span id="cb338-8"><a href="#cb338-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb338-9"><a href="#cb338-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-----"</span>)</span>
<span id="cb338-10"><a href="#cb338-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb338-11"><a href="#cb338-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.transpose(1, 0).shape: </span><span class="ch">\n</span><span class="st">"</span>, x.transpose(<span class="dv">1</span>, <span class="dv">0</span>).shape)</span>
<span id="cb338-12"><a href="#cb338-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.transpose(1, 0): </span><span class="ch">\n</span><span class="st">"</span>, x.transpose(<span class="dv">1</span>, <span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x.shape: 
 torch.Size([3, 4, 5])
x: 
 tensor([[[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14],
         [15, 16, 17, 18, 19]],

        [[20, 21, 22, 23, 24],
         [25, 26, 27, 28, 29],
         [30, 31, 32, 33, 34],
         [35, 36, 37, 38, 39]],

        [[40, 41, 42, 43, 44],
         [45, 46, 47, 48, 49],
         [50, 51, 52, 53, 54],
         [55, 56, 57, 58, 59]]])
-----
x.transpose(1, 0).shape: 
 torch.Size([4, 3, 5])
x.transpose(1, 0): 
 tensor([[[ 0,  1,  2,  3,  4],
         [20, 21, 22, 23, 24],
         [40, 41, 42, 43, 44]],

        [[ 5,  6,  7,  8,  9],
         [25, 26, 27, 28, 29],
         [45, 46, 47, 48, 49]],

        [[10, 11, 12, 13, 14],
         [30, 31, 32, 33, 34],
         [50, 51, 52, 53, 54]],

        [[15, 16, 17, 18, 19],
         [35, 36, 37, 38, 39],
         [55, 56, 57, 58, 59]]])</code></pre>
</div>
</div>
<p>Permute is a more general version of tranpose:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb340"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb340-1"><a href="#cb340-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb340-2"><a href="#cb340-2" aria-hidden="true" tabindex="-1"></a>seq_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb340-3"><a href="#cb340-3" aria-hidden="true" tabindex="-1"></a>feature_size <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb340-4"><a href="#cb340-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-5"><a href="#cb340-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(batch_size <span class="op">*</span> seq_size <span class="op">*</span> feature_size).view(batch_size, seq_size, feature_size)</span>
<span id="cb340-6"><a href="#cb340-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-7"><a href="#cb340-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.shape: </span><span class="ch">\n</span><span class="st">"</span>, x.shape)</span>
<span id="cb340-8"><a href="#cb340-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb340-9"><a href="#cb340-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-----"</span>)</span>
<span id="cb340-10"><a href="#cb340-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb340-11"><a href="#cb340-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.permute(1, 0, 2).shape: </span><span class="ch">\n</span><span class="st">"</span>, x.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>).shape)</span>
<span id="cb340-12"><a href="#cb340-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x.permute(1, 0, 2): </span><span class="ch">\n</span><span class="st">"</span>, x.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x.shape: 
 torch.Size([3, 4, 5])
x: 
 tensor([[[ 0,  1,  2,  3,  4],
         [ 5,  6,  7,  8,  9],
         [10, 11, 12, 13, 14],
         [15, 16, 17, 18, 19]],

        [[20, 21, 22, 23, 24],
         [25, 26, 27, 28, 29],
         [30, 31, 32, 33, 34],
         [35, 36, 37, 38, 39]],

        [[40, 41, 42, 43, 44],
         [45, 46, 47, 48, 49],
         [50, 51, 52, 53, 54],
         [55, 56, 57, 58, 59]]])
-----
x.permute(1, 0, 2).shape: 
 torch.Size([4, 3, 5])
x.permute(1, 0, 2): 
 tensor([[[ 0,  1,  2,  3,  4],
         [20, 21, 22, 23, 24],
         [40, 41, 42, 43, 44]],

        [[ 5,  6,  7,  8,  9],
         [25, 26, 27, 28, 29],
         [45, 46, 47, 48, 49]],

        [[10, 11, 12, 13, 14],
         [30, 31, 32, 33, 34],
         [50, 51, 52, 53, 54]],

        [[15, 16, 17, 18, 19],
         [35, 36, 37, 38, 39],
         [55, 56, 57, 58, 59]]])</code></pre>
</div>
</div>
<p>Matrix multiplication is <code>mm</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb342"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a>torch.randn(<span class="dv">2</span>, <span class="dv">3</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([[-0.4790,  0.8539, -0.2285],
        [ 0.3081,  1.1171,  0.1585]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb344"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb344-1"><a href="#cb344-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="op">=</span> torch.arange(<span class="dv">6</span>).view(<span class="dv">2</span>, <span class="dv">3</span>).<span class="bu">float</span>()</span>
<span id="cb344-2"><a href="#cb344-2" aria-hidden="true" tabindex="-1"></a>describe(x1)</span>
<span id="cb344-3"><a href="#cb344-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-4"><a href="#cb344-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.ones(<span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb344-5"><a href="#cb344-5" aria-hidden="true" tabindex="-1"></a>x2[:, <span class="dv">1</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb344-6"><a href="#cb344-6" aria-hidden="true" tabindex="-1"></a>describe(x2)</span>
<span id="cb344-7"><a href="#cb344-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb344-8"><a href="#cb344-8" aria-hidden="true" tabindex="-1"></a>describe(torch.mm(x1, x2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.FloatTensor
Shape/size: torch.Size([2, 3])
Values: 
tensor([[0., 1., 2.],
        [3., 4., 5.]])
Type: torch.FloatTensor
Shape/size: torch.Size([3, 2])
Values: 
tensor([[1., 2.],
        [1., 2.],
        [1., 2.]])
Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[ 3.,  6.],
        [12., 24.]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb346"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb346-1"><a href="#cb346-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.arange(<span class="dv">0</span>, <span class="dv">12</span>).view(<span class="dv">3</span>,<span class="dv">4</span>).<span class="bu">float</span>()</span>
<span id="cb346-2"><a href="#cb346-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x)</span>
<span id="cb346-3"><a href="#cb346-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb346-4"><a href="#cb346-4" aria-hidden="true" tabindex="-1"></a>x2 <span class="op">=</span> torch.ones(<span class="dv">4</span>, <span class="dv">2</span>)</span>
<span id="cb346-5"><a href="#cb346-5" aria-hidden="true" tabindex="-1"></a>x2[:, <span class="dv">1</span>] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb346-6"><a href="#cb346-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x2)</span>
<span id="cb346-7"><a href="#cb346-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb346-8"><a href="#cb346-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.mm(x2))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  5.,  6.,  7.],
        [ 8.,  9., 10., 11.]])
tensor([[1., 2.],
        [1., 2.],
        [1., 2.],
        [1., 2.]])
tensor([[ 6., 12.],
        [22., 44.],
        [38., 76.]])</code></pre>
</div>
</div>
<p>See the <a href="https://pytorch.org/docs/stable/torch.html#math-operations">PyTorch Math Operations Documentation</a> for more!</p>
</section>
</section>
<section id="computing-gradients" class="level2">
<h2 class="anchored" data-anchor-id="computing-gradients">Computing Gradients</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb348"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">2.0</span>, <span class="fl">3.0</span>]], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb348-2"><a href="#cb348-2" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> <span class="dv">3</span> <span class="op">*</span> x</span>
<span id="cb348-3"><a href="#cb348-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(z)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[6., 9.]], grad_fn=&lt;MulBackward0&gt;)</code></pre>
</div>
</div>
<p>In this small snippet, you can see the gradient computations at work. We create a tensor and multiply it by 3. Then, we create a scalar output using <code>sum()</code>. A Scalar output is needed as the the loss variable. Then, called backward on the loss means it computes its rate of change with respect to the inputs. Since the scalar was created with sum, each position in z and x are independent with respect to the loss scalar.</p>
<p>The rate of change of x with respect to the output is just the constant 3 that we multiplied x by.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb350"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([[<span class="fl">2.0</span>, <span class="fl">3.0</span>]], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb350-2"><a href="#cb350-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"x: </span><span class="ch">\n</span><span class="st">"</span>, x)</span>
<span id="cb350-3"><a href="#cb350-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb350-4"><a href="#cb350-4" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> <span class="dv">3</span> <span class="op">*</span> x</span>
<span id="cb350-5"><a href="#cb350-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"z = 3*x: </span><span class="ch">\n</span><span class="st">"</span>, z)</span>
<span id="cb350-6"><a href="#cb350-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb350-7"><a href="#cb350-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb350-8"><a href="#cb350-8" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> z.<span class="bu">sum</span>()</span>
<span id="cb350-9"><a href="#cb350-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"loss = z.sum(): </span><span class="ch">\n</span><span class="st">"</span>, loss)</span>
<span id="cb350-10"><a href="#cb350-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"---"</span>)</span>
<span id="cb350-11"><a href="#cb350-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb350-12"><a href="#cb350-12" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb350-13"><a href="#cb350-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb350-14"><a href="#cb350-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"after loss.backward(), x.grad: </span><span class="ch">\n</span><span class="st">"</span>, x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x: 
 tensor([[2., 3.]], requires_grad=True)
---
z = 3*x: 
 tensor([[6., 9.]], grad_fn=&lt;MulBackward0&gt;)
---
loss = z.sum(): 
 tensor(15., grad_fn=&lt;SumBackward0&gt;)
---
after loss.backward(), x.grad: 
 tensor([[3., 3.]])</code></pre>
</div>
</div>
<section id="example-computing-a-conditional-gradient" class="level3">
<h3 class="anchored" data-anchor-id="example-computing-a-conditional-gradient">Example: Computing a conditional gradient</h3>
<p><span class="math display">\[ \text{ Find the gradient of f(x) at x=1 } \]</span></p>
<p><span class="math display">\[ {} \]</span></p>
<p><span class="math display">\[ f(x)=\left\{
\begin{array}{ll}
    sin(x) \text{ if } x&gt;0 \\
    cos(x) \text{ otherwise } \\
\end{array}
\right.\]</span></p>
<div class="sourceCode cell-code" id="cb352"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb352-1"><a href="#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(x):</span>
<span id="cb352-2"><a href="#cb352-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (x.data <span class="op">&gt;</span> <span class="dv">0</span>).<span class="bu">all</span>():</span>
<span id="cb352-3"><a href="#cb352-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.sin(x)</span>
<span id="cb352-4"><a href="#cb352-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb352-5"><a href="#cb352-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> torch.cos(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb353"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb353-1"><a href="#cb353-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb353-2"><a href="#cb353-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb353-3"><a href="#cb353-3" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb353-4"><a href="#cb353-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.5403])</code></pre>
</div>
</div>
<p>We could apply this to a larger vector too, but we need to make sure the output is a scalar:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb355"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb355-1"><a href="#cb355-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">0.5</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb355-2"><a href="#cb355-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb355-3"><a href="#cb355-3" aria-hidden="true" tabindex="-1"></a><span class="co"># this is meant to break!</span></span>
<span id="cb355-4"><a href="#cb355-4" aria-hidden="true" tabindex="-1"></a>y.backward()</span>
<span id="cb355-5"><a href="#cb355-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: grad can be implicitly created only for scalar outputs</code></pre>
</div>
</div>
<p>Making the output a scalar:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb357"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb357-1"><a href="#cb357-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">0.5</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb357-2"><a href="#cb357-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb357-3"><a href="#cb357-3" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb357-4"><a href="#cb357-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.5403, 0.8776])</code></pre>
</div>
</div>
<p>but there was an issue.. this isn’t right for this edge case:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb359"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb359-1"><a href="#cb359-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="op">-</span><span class="dv">1</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb359-2"><a href="#cb359-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb359-3"><a href="#cb359-3" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb359-4"><a href="#cb359-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([-0.8415,  0.8415])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb361"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb361-1"><a href="#cb361-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">0.5</span>, <span class="op">-</span><span class="dv">1</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb361-2"><a href="#cb361-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f(x)</span>
<span id="cb361-3"><a href="#cb361-3" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb361-4"><a href="#cb361-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.4794, 0.8415])</code></pre>
</div>
</div>
<p>This is because we aren’t doing the boolean computation and subsequent application of cos and sin on an elementwise basis. So, to solve this, it is common to use masking:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb363"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb363-1"><a href="#cb363-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f2(x):</span>
<span id="cb363-2"><a href="#cb363-2" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> torch.gt(x, <span class="dv">0</span>).<span class="bu">float</span>()</span>
<span id="cb363-3"><a href="#cb363-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mask <span class="op">*</span> torch.sin(x) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> mask) <span class="op">*</span> torch.cos(x)</span>
<span id="cb363-4"><a href="#cb363-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb363-5"><a href="#cb363-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="op">-</span><span class="dv">1</span>], requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb363-6"><a href="#cb363-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> f2(x)</span>
<span id="cb363-7"><a href="#cb363-7" aria-hidden="true" tabindex="-1"></a>y.<span class="bu">sum</span>().backward()</span>
<span id="cb363-8"><a href="#cb363-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.grad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([0.5403, 0.8415])</code></pre>
</div>
</div>
<div class="sourceCode cell-code" id="cb365"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb365-1"><a href="#cb365-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> describe_grad(x):</span>
<span id="cb365-2"><a href="#cb365-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> x.grad <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb365-3"><a href="#cb365-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"No gradient information"</span>)</span>
<span id="cb365-4"><a href="#cb365-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb365-5"><a href="#cb365-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Gradient: </span><span class="ch">\n</span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(x.grad))</span>
<span id="cb365-6"><a href="#cb365-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Gradient Function: </span><span class="sc">{}</span><span class="st">"</span>.<span class="bu">format</span>(x.grad_fn))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb366"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb366-2"><a href="#cb366-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb366-3"><a href="#cb366-3" aria-hidden="true" tabindex="-1"></a>describe(x)</span>
<span id="cb366-4"><a href="#cb366-4" aria-hidden="true" tabindex="-1"></a>describe_grad(x)</span>
<span id="cb366-5"><a href="#cb366-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------"</span>)</span>
<span id="cb366-6"><a href="#cb366-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb366-7"><a href="#cb366-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (x <span class="op">+</span> <span class="dv">2</span>) <span class="op">*</span> (x <span class="op">+</span> <span class="dv">5</span>) <span class="op">+</span> <span class="dv">3</span></span>
<span id="cb366-8"><a href="#cb366-8" aria-hidden="true" tabindex="-1"></a>describe(y)</span>
<span id="cb366-9"><a href="#cb366-9" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> y.mean()</span>
<span id="cb366-10"><a href="#cb366-10" aria-hidden="true" tabindex="-1"></a>describe(z)</span>
<span id="cb366-11"><a href="#cb366-11" aria-hidden="true" tabindex="-1"></a>describe_grad(x)</span>
<span id="cb366-12"><a href="#cb366-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------"</span>)</span>
<span id="cb366-13"><a href="#cb366-13" aria-hidden="true" tabindex="-1"></a>z.backward(create_graph<span class="op">=</span><span class="va">True</span>, retain_graph<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb366-14"><a href="#cb366-14" aria-hidden="true" tabindex="-1"></a>describe_grad(x)</span>
<span id="cb366-15"><a href="#cb366-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"--------"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
No gradient information
--------
Type: torch.FloatTensor
Shape/size: torch.Size([2, 2])
Values: 
tensor([[21., 21.],
        [21., 21.]], grad_fn=&lt;AddBackward0&gt;)
Type: torch.FloatTensor
Shape/size: torch.Size([])
Values: 
21.0
No gradient information
--------
Gradient: 
tensor([[2.2500, 2.2500],
        [2.2500, 2.2500]], grad_fn=&lt;CloneBackward&gt;)
Gradient Function: None
--------</code></pre>
</div>
</div>
<div class="sourceCode cell-code" id="cb368"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb368-1"><a href="#cb368-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.ones(<span class="dv">2</span>, <span class="dv">2</span>, requires_grad<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="sourceCode cell-code" id="cb369"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb369-1"><a href="#cb369-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> x <span class="op">+</span> <span class="dv">2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb370"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb370-1"><a href="#cb370-1" aria-hidden="true" tabindex="-1"></a>y.grad_fn</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>&lt;AddBackward0 at 0x7f35ea134940&gt;</code></pre>
</div>
</div>
</section>
<section id="cuda-tensors" class="level3">
<h3 class="anchored" data-anchor-id="cuda-tensors">CUDA Tensors</h3>
<p>PyTorch’s operations can seamlessly be used on the GPU or on the CPU. There are a couple basic operations for interacting in this way.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb372"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb372-1"><a href="#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.cuda.is_available())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb374"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb374-1"><a href="#cb374-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb374-2"><a href="#cb374-2" aria-hidden="true" tabindex="-1"></a>describe(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.FloatTensor
Shape/size: torch.Size([3, 3])
Values: 
tensor([[0.9149, 0.3993, 0.1100],
        [0.2541, 0.4333, 0.4451],
        [0.4966, 0.7865, 0.6604]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb376"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb376-1"><a href="#cb376-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb376-2"><a href="#cb376-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>cuda</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb378"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb378-1"><a href="#cb378-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">3</span>).to(device)</span>
<span id="cb378-2"><a href="#cb378-2" aria-hidden="true" tabindex="-1"></a>describe(x)</span>
<span id="cb378-3"><a href="#cb378-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(x.device)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Type: torch.cuda.FloatTensor
Shape/size: torch.Size([3, 3])
Values: 
tensor([[0.1303, 0.3498, 0.3824],
        [0.8043, 0.3186, 0.2908],
        [0.4196, 0.3728, 0.3769]], device='cuda:0')
cuda:0</code></pre>
</div>
</div>
<div class="sourceCode cell-code" id="cb380"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb380-1"><a href="#cb380-1" aria-hidden="true" tabindex="-1"></a>cpu_device <span class="op">=</span> torch.device(<span class="st">"cpu"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell">
<div class="sourceCode cell-code" id="cb381"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb381-1"><a href="#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this will break!</span></span>
<span id="cb381-2"><a href="#cb381-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> torch.rand(<span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb381-3"><a href="#cb381-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">+</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: expected type torch.cuda.FloatTensor but got torch.FloatTensor</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb383"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb383-1"><a href="#cb383-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y.to(cpu_device)</span>
<span id="cb383-2"><a href="#cb383-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.to(cpu_device)</span>
<span id="cb383-3"><a href="#cb383-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">+</span> y</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>tensor([[0.8394, 0.5273, 0.8267],
        [0.9273, 1.2824, 1.0603],
        [0.4574, 0.5968, 1.0541]])</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb385"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb385-1"><a href="#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available(): <span class="co"># only is GPU is available</span></span>
<span id="cb385-2"><a href="#cb385-2" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>).to(device<span class="op">=</span><span class="st">'cuda:0'</span>) <span class="co">#  CUDA Tensor</span></span>
<span id="cb385-3"><a href="#cb385-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a)</span>
<span id="cb385-4"><a href="#cb385-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb385-5"><a href="#cb385-5" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>).cuda()</span>
<span id="cb385-6"><a href="#cb385-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(b)</span>
<span id="cb385-7"><a href="#cb385-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb385-8"><a href="#cb385-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a <span class="op">+</span> b)</span>
<span id="cb385-9"><a href="#cb385-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb385-10"><a href="#cb385-10" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> a.cpu() <span class="co"># Error expected</span></span>
<span id="cb385-11"><a href="#cb385-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(a <span class="op">+</span> b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[0.5274, 0.6325, 0.0910],
        [0.2323, 0.7269, 0.1187],
        [0.3951, 0.7199, 0.7595]], device='cuda:0')
tensor([[0.5311, 0.6449, 0.7224],
        [0.4416, 0.3634, 0.8818],
        [0.9874, 0.7316, 0.2814]], device='cuda:0')
tensor([[1.0585, 1.2775, 0.8134],
        [0.6739, 1.0903, 1.0006],
        [1.3825, 1.4515, 1.0409]], device='cuda:0')</code></pre>
</div>
<div class="cell-output cell-output-error">
<pre><code>RuntimeError: expected type torch.FloatTensor but got torch.cuda.FloatTensor</code></pre>
</div>
</div>
</section>
<section id="exercises-1" class="level3">
<h3 class="anchored" data-anchor-id="exercises-1">Exercises</h3>
<p>Some of these exercises require operations not covered in the notebook. You will have to look at <a href="https://pytorch.org/docs/">the documentation</a> (on purpose!)</p>
<p>(Answers are at the bottom)</p>
<section id="exercise-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-1">Exercise 1</h4>
<p>Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.</p>
</section>
<section id="exercise-2" class="level4">
<h4 class="anchored" data-anchor-id="exercise-2">Exercise 2</h4>
<p>Remove the extra dimension you just added to the previous tensor.</p>
</section>
<section id="exercise-3" class="level4">
<h4 class="anchored" data-anchor-id="exercise-3">Exercise 3</h4>
<p>Create a random tensor of shape 5x3 in the interval [3, 7)</p>
</section>
<section id="exercise-4" class="level4">
<h4 class="anchored" data-anchor-id="exercise-4">Exercise 4</h4>
<p>Create a tensor with values from a normal distribution (mean=0, std=1).</p>
</section>
<section id="exercise-5" class="level4">
<h4 class="anchored" data-anchor-id="exercise-5">Exercise 5</h4>
<p>Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).</p>
</section>
<section id="exercise-6" class="level4">
<h4 class="anchored" data-anchor-id="exercise-6">Exercise 6</h4>
<p>Create a random tensor of size (3,1) and then horizonally stack 4 copies together.</p>
</section>
<section id="exercise-7" class="level4">
<h4 class="anchored" data-anchor-id="exercise-7">Exercise 7</h4>
<p>Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).</p>
</section>
<section id="exercise-8" class="level4">
<h4 class="anchored" data-anchor-id="exercise-8">Exercise 8</h4>
<p>Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).</p>
<p>Answers below</p>
<p>Answers still below.. Keep Going</p>
</section>
<section id="exercise-1-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-1-1">Exercise 1</h4>
<p>Create a 2D tensor and then add a dimension of size 1 inserted at the 0th axis.</p>
<div class="sourceCode cell-code" id="cb388"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb388-1"><a href="#cb388-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb388-2"><a href="#cb388-2" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> a.unsqueeze(<span class="dv">0</span>)</span>
<span id="cb388-3"><a href="#cb388-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a)</span>
<span id="cb388-4"><a href="#cb388-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-2-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-2-1">Exercise 2</h4>
<p>Remove the extra dimension you just added to the previous tensor.</p>
<div class="sourceCode cell-code" id="cb389"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb389-1"><a href="#cb389-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> a.squeeze(<span class="dv">0</span>)</span>
<span id="cb389-2"><a href="#cb389-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(a.shape)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-3-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-3-1">Exercise 3</h4>
<p>Create a random tensor of shape 5x3 in the interval [3, 7)</p>
<div class="sourceCode cell-code" id="cb390"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb390-1"><a href="#cb390-1" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> <span class="op">+</span> torch.rand(<span class="dv">5</span>, <span class="dv">3</span>) <span class="op">*</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-4-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-4-1">Exercise 4</h4>
<p>Create a tensor with values from a normal distribution (mean=0, std=1).</p>
<div class="sourceCode cell-code" id="cb391"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb391-1"><a href="#cb391-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">3</span>)</span>
<span id="cb391-2"><a href="#cb391-2" aria-hidden="true" tabindex="-1"></a>a.normal_(mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-5-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-5-1">Exercise 5</h4>
<p>Retrieve the indexes of all the non zero elements in the tensor torch.Tensor([1, 1, 1, 0, 1]).</p>
<div class="sourceCode cell-code" id="cb392"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb392-1"><a href="#cb392-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.Tensor([<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb392-2"><a href="#cb392-2" aria-hidden="true" tabindex="-1"></a>torch.nonzero(a)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-6-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-6-1">Exercise 6</h4>
<p>Create a random tensor of size (3,1) and then horizonally stack 4 copies together.</p>
<div class="sourceCode cell-code" id="cb393"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb393-1"><a href="#cb393-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">1</span>)</span>
<span id="cb393-2"><a href="#cb393-2" aria-hidden="true" tabindex="-1"></a>a.expand(<span class="dv">3</span>,<span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-7-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-7-1">Exercise 7</h4>
<p>Return the batch matrix-matrix product of two 3 dimensional matrices (a=torch.rand(3,4,5), b=torch.rand(3,5,4)).</p>
<div class="sourceCode cell-code" id="cb394"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)</span>
<span id="cb394-2"><a href="#cb394-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">4</span>)</span>
<span id="cb394-3"><a href="#cb394-3" aria-hidden="true" tabindex="-1"></a>torch.bmm(a, b)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="exercise-8-1" class="level4">
<h4 class="anchored" data-anchor-id="exercise-8-1">Exercise 8</h4>
<p>Return the batch matrix-matrix product of a 3D matrix and a 2D matrix (a=torch.rand(3,4,5), b=torch.rand(5,4)).</p>
<div class="sourceCode cell-code" id="cb395"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb395-1"><a href="#cb395-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> torch.rand(<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)</span>
<span id="cb395-2"><a href="#cb395-2" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> torch.rand(<span class="dv">5</span>,<span class="dv">4</span>)</span>
<span id="cb395-3"><a href="#cb395-3" aria-hidden="true" tabindex="-1"></a>torch.bmm(a, b.unsqueeze(<span class="dv">0</span>).expand(a.size(<span class="dv">0</span>), <span class="op">*</span>b.size()))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="end" class="level3">
<h3 class="anchored" data-anchor-id="end">END</h3>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="shmuhammad2004/shmuhammadblog" data-repo-id="R_kgDOHb5q2A" data-category="Announcements" data-category-id="DIC_kwDOHb5q2M4CPbHo" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../license.html">License</a>
  </li>  
</ul>
    </div>   
  </div>
</footer>



</body></html>